06:06:51	Optimizer: adam
06:06:51	Optimizer params: {'lr': 0.02}
06:06:51	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
06:06:51	nLayers: 1 - nEpochs: 40 - batchSize: 32
06:06:51	Cost: fidelity
06:06:51	Seed: None

------------------------------

06:06:53	epoch	loss	accuracy
06:06:56	    0	0.496	   0.508
06:07:03	    1	0.492	   0.508
06:07:09	    2	0.492	   0.508
06:07:16	    3	0.490	   0.508
06:07:22	    4	0.471	   0.508
06:07:29	    5	0.375	   0.646
06:07:37	    6	0.291	   0.750
06:07:44	    7	0.271	   0.762
06:07:50	    8	0.269	   0.762
06:07:57	    9	0.269	   0.762
06:08:04	   10	0.269	   0.764
06:08:12	   11	0.269	   0.762
06:08:18	   12	0.269	   0.764
06:08:25	   13	0.269	   0.762
06:08:32	   14	0.269	   0.762
06:08:38	   15	0.269	   0.762
06:08:46	   16	0.269	   0.762
06:08:53	   17	0.269	   0.762
06:09:00	   18	0.269	   0.764
06:09:06	   19	0.269	   0.762
06:09:13	   20	0.269	   0.764
06:09:21	   21	0.269	   0.762
06:09:28	   22	0.269	   0.762
06:09:34	   23	0.269	   0.762
06:09:41	   24	0.269	   0.762
06:09:47	   25	0.269	   0.762
06:09:56	   26	0.269	   0.762
06:10:02	   27	0.269	   0.762
06:10:09	   28	0.269	   0.762
06:10:16	   29	0.269	   0.762
06:10:22	   30	0.269	   0.762
06:10:31	   31	0.269	   0.764
06:10:37	   32	0.269	   0.764
06:10:44	   33	0.269	   0.764
06:10:50	   34	0.269	   0.764
06:10:57	   35	0.269	   0.762
06:11:06	   36	0.269	   0.762
06:11:12	   37	0.269	   0.762
06:11:19	   38	0.269	   0.764
06:11:25	   39	0.269	   0.764
06:11:32	   40	0.269	   0.764

------------------------------

06:11:34	Parameters at epoch 40:

06:11:34	Theta:
06:11:34		-0.0000  -1.6034  -2.3364  
06:11:34	Alpha:
06:11:34		-0.4295   2.0566  

------------------------------

06:11:43	Accuracy on test set with the parameters above: 0.733

