06:06:11	Optimizer: adam
06:06:11	Optimizer params: {'lr': 0.02}
06:06:11	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
06:06:11	nLayers: 1 - nEpochs: 40 - batchSize: 32
06:06:11	Cost: fidelity
06:06:11	Seed: None

------------------------------

06:06:13	epoch	loss	accuracy
06:06:15	    0	0.510	   0.498
06:06:21	    1	0.473	   0.640
06:06:28	    2	0.416	   0.718
06:06:34	    3	0.353	   0.748
06:06:41	    4	0.312	   0.746
06:06:47	    5	0.298	   0.738
06:06:55	    6	0.295	   0.744
06:07:01	    7	0.294	   0.742
06:07:08	    8	0.294	   0.742
06:07:14	    9	0.294	   0.742
06:07:20	   10	0.294	   0.742
06:07:29	   11	0.294	   0.742
06:07:35	   12	0.294	   0.742
06:07:41	   13	0.294	   0.744
06:07:48	   14	0.294	   0.742
06:07:54	   15	0.294	   0.742
06:08:02	   16	0.294	   0.744
06:08:09	   17	0.294	   0.744
06:08:15	   18	0.294	   0.744
06:08:22	   19	0.294	   0.744
06:08:28	   20	0.294	   0.742
06:08:36	   21	0.294	   0.742
06:08:43	   22	0.294	   0.744
06:08:50	   23	0.294	   0.744
06:08:56	   24	0.294	   0.744
06:09:03	   25	0.294	   0.744
06:09:11	   26	0.294	   0.744
06:09:18	   27	0.294	   0.744
06:09:24	   28	0.294	   0.742
06:09:30	   29	0.294	   0.742
06:09:37	   30	0.294	   0.744
06:09:45	   31	0.294	   0.742
06:09:52	   32	0.294	   0.744
06:09:58	   33	0.294	   0.744
06:10:05	   34	0.294	   0.742
06:10:11	   35	0.294	   0.742
06:10:20	   36	0.294	   0.742
06:10:26	   37	0.294	   0.744
06:10:32	   38	0.294	   0.742
06:10:39	   39	0.294	   0.742
06:10:46	   40	0.294	   0.742

------------------------------

06:10:47	Parameters at epoch 40:

06:10:47	Theta:
06:10:47		 0.0000  -1.5281   0.4627  
06:10:47	Alpha:
06:10:47		 0.2921   2.0675  

------------------------------

06:10:56	Accuracy on test set with the parameters above: 0.7533333333333333

