06:06:37	Optimizer: adam
06:06:37	Optimizer params: {'lr': 0.02}
06:06:37	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
06:06:37	nLayers: 1 - nEpochs: 40 - batchSize: 32
06:06:37	Cost: fidelity
06:06:37	Seed: None

------------------------------

06:06:41	epoch	loss	accuracy
06:06:43	    0	0.525	   0.476
06:06:51	    1	0.516	   0.476
06:06:58	    2	0.463	   0.476
06:07:05	    3	0.376	   0.682
06:07:12	    4	0.303	   0.740
06:07:20	    5	0.274	   0.766
06:07:29	    6	0.267	   0.780
06:07:36	    7	0.266	   0.780
06:07:44	    8	0.266	   0.774
06:07:51	    9	0.266	   0.768
06:07:58	   10	0.266	   0.768
06:08:08	   11	0.266	   0.774
06:08:15	   12	0.266	   0.768
06:08:22	   13	0.266	   0.774
06:08:29	   14	0.266	   0.774
06:08:37	   15	0.266	   0.768
06:08:46	   16	0.266	   0.774
06:08:53	   17	0.266	   0.774
06:09:00	   18	0.266	   0.768
06:09:08	   19	0.266	   0.772
06:09:15	   20	0.266	   0.772
06:09:24	   21	0.266	   0.772
06:09:32	   22	0.266	   0.768
06:09:39	   23	0.266	   0.772
06:09:46	   24	0.266	   0.774
06:09:54	   25	0.266	   0.772
06:10:04	   26	0.266	   0.768
06:10:11	   27	0.266	   0.772
06:10:19	   28	0.266	   0.770
06:10:26	   29	0.266	   0.772
06:10:34	   30	0.266	   0.768
06:10:43	   31	0.266	   0.772
06:10:50	   32	0.266	   0.772
06:10:58	   33	0.266	   0.772
06:11:05	   34	0.266	   0.774
06:11:13	   35	0.266	   0.772
06:11:22	   36	0.266	   0.770
06:11:29	   37	0.266	   0.768
06:11:37	   38	0.266	   0.772
06:11:44	   39	0.266	   0.772
06:11:51	   40	0.266	   0.768

------------------------------

06:11:53	Parameters at epoch 40:

06:11:53	Theta:
06:11:53		 0.0000   1.5125  -1.5268  
06:11:53	Alpha:
06:11:53		 0.1932  -2.1102  

------------------------------

06:12:03	Accuracy on test set with the parameters above: 0.7473333333333333

