06:06:58	Optimizer: adam
06:06:58	Optimizer params: {'lr': 0.02}
06:06:58	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
06:06:58	nLayers: 1 - nEpochs: 40 - batchSize: 32
06:06:58	Cost: fidelity
06:06:58	Seed: None

------------------------------

06:07:01	epoch	loss	accuracy
06:07:03	    0	0.433	   0.598
06:07:10	    1	0.370	   0.734
06:07:17	    2	0.325	   0.734
06:07:23	    3	0.302	   0.744
06:07:30	    4	0.290	   0.742
06:07:37	    5	0.285	   0.738
06:07:46	    6	0.284	   0.732
06:07:53	    7	0.283	   0.734
06:07:59	    8	0.283	   0.732
06:08:06	    9	0.283	   0.734
06:08:13	   10	0.283	   0.732
06:08:22	   11	0.283	   0.734
06:08:29	   12	0.283	   0.732
06:08:35	   13	0.283	   0.732
06:08:42	   14	0.283	   0.732
06:08:49	   15	0.283	   0.734
06:08:58	   16	0.283	   0.734
06:09:05	   17	0.283	   0.734
06:09:11	   18	0.283	   0.734
06:09:18	   19	0.283	   0.734
06:09:25	   20	0.283	   0.734
06:09:34	   21	0.283	   0.734
06:09:41	   22	0.283	   0.732
06:09:48	   23	0.283	   0.732
06:09:54	   24	0.283	   0.734
06:10:01	   25	0.283	   0.732
06:10:10	   26	0.283	   0.732
06:10:17	   27	0.283	   0.732
06:10:24	   28	0.283	   0.732
06:10:31	   29	0.283	   0.732
06:10:37	   30	0.283	   0.734
06:10:46	   31	0.283	   0.732
06:10:53	   32	0.283	   0.732
06:11:00	   33	0.283	   0.734
06:11:07	   34	0.283	   0.732
06:11:13	   35	0.283	   0.732
06:11:22	   36	0.283	   0.732
06:11:29	   37	0.283	   0.732
06:11:36	   38	0.283	   0.734
06:11:43	   39	0.283	   0.732
06:11:50	   40	0.283	   0.734

------------------------------

06:11:52	Parameters at epoch 40:

06:11:52	Theta:
06:11:52		 0.0000   1.6022  -1.0876  
06:11:52	Alpha:
06:11:52		 0.0965  -2.1058  

------------------------------

06:12:01	Accuracy on test set with the parameters above: 0.755

