05:58:16	Optimizer: adam
05:58:16	Optimizer params: {'lr': 0.02}
05:58:16	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:58:16	nLayers: 1 - nEpochs: 40 - batchSize: 32
05:58:16	Cost: weighted fidelity
05:58:16	Seed: None

------------------------------

05:58:18	epoch	loss	accuracy
05:58:21	    0	0.444	   0.504
05:58:34	    1	0.278	   0.504
05:58:47	    2	0.206	   0.720
05:58:59	    3	0.194	   0.718
05:59:12	    4	0.189	   0.728
05:59:25	    5	0.189	   0.726
05:59:39	    6	0.187	   0.726
05:59:52	    7	0.186	   0.728
06:00:05	    8	0.185	   0.728
06:00:17	    9	0.184	   0.730
06:00:30	   10	0.183	   0.726
06:00:45	   11	0.182	   0.730
06:00:58	   12	0.182	   0.730
06:01:11	   13	0.181	   0.732
06:01:24	   14	0.181	   0.734
06:01:36	   15	0.181	   0.730
06:01:51	   16	0.180	   0.732
06:02:04	   17	0.180	   0.730
06:02:16	   18	0.180	   0.736
06:02:29	   19	0.180	   0.736
06:02:42	   20	0.180	   0.730
06:02:57	   21	0.180	   0.736
06:03:10	   22	0.180	   0.734
06:03:22	   23	0.180	   0.736
06:03:35	   24	0.180	   0.730
06:03:48	   25	0.180	   0.736
06:04:03	   26	0.180	   0.736
06:04:16	   27	0.180	   0.736
06:04:28	   28	0.180	   0.734
06:04:41	   29	0.180	   0.734
06:04:53	   30	0.180	   0.736
06:05:08	   31	0.180	   0.736
06:05:21	   32	0.180	   0.736
06:05:33	   33	0.180	   0.736
06:05:46	   34	0.180	   0.736
06:05:59	   35	0.180	   0.736
06:06:13	   36	0.180	   0.736
06:06:26	   37	0.180	   0.734
06:06:39	   38	0.180	   0.736
06:06:51	   39	0.180	   0.736
06:07:04	   40	0.180	   0.736

------------------------------

06:07:06	Parameters at epoch 40:

06:07:06	Theta:
06:07:06		 0.0000   1.5273  -1.8019  
06:07:06	Alpha:
06:07:06		 0.8960  -1.0204  
06:07:06	Class weight:
06:07:06		 0.9892   1.0104  

------------------------------

06:07:16	Accuracy on test set with the parameters above: 0.742

