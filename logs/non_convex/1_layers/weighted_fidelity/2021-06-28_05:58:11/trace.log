05:58:11	Optimizer: adam
05:58:11	Optimizer params: {'lr': 0.02}
05:58:11	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:58:11	nLayers: 1 - nEpochs: 40 - batchSize: 32
05:58:11	Cost: weighted fidelity
05:58:11	Seed: None

------------------------------

05:58:13	epoch	loss	accuracy
05:58:16	    0	0.482	   0.480
05:58:27	    1	0.339	   0.480
05:58:39	    2	0.264	   0.344
05:58:50	    3	0.240	   0.520
05:59:01	    4	0.215	   0.728
05:59:13	    5	0.198	   0.730
05:59:26	    6	0.195	   0.736
05:59:37	    7	0.193	   0.734
05:59:48	    8	0.191	   0.734
06:00:00	    9	0.190	   0.732
06:00:11	   10	0.189	   0.736
06:00:24	   11	0.188	   0.730
06:00:35	   12	0.186	   0.732
06:00:47	   13	0.186	   0.730
06:00:58	   14	0.185	   0.734
06:01:09	   15	0.184	   0.732
06:01:23	   16	0.184	   0.730
06:01:34	   17	0.184	   0.732
06:01:46	   18	0.183	   0.734
06:01:57	   19	0.183	   0.734
06:02:09	   20	0.183	   0.732
06:02:22	   21	0.183	   0.730
06:02:33	   22	0.183	   0.736
06:02:44	   23	0.183	   0.734
06:02:56	   24	0.183	   0.734
06:03:07	   25	0.183	   0.734
06:03:20	   26	0.183	   0.736
06:03:31	   27	0.183	   0.732
06:03:43	   28	0.182	   0.734
06:03:54	   29	0.182	   0.734
06:04:06	   30	0.182	   0.734
06:04:19	   31	0.182	   0.736
06:04:30	   32	0.182	   0.736
06:04:42	   33	0.182	   0.732
06:04:53	   34	0.182	   0.734
06:05:04	   35	0.182	   0.732
06:05:17	   36	0.182	   0.734
06:05:29	   37	0.182	   0.734
06:05:40	   38	0.182	   0.734
06:05:51	   39	0.182	   0.734
06:06:03	   40	0.182	   0.734

------------------------------

06:06:05	Parameters at epoch 40:

06:06:05	Theta:
06:06:05		 0.2269  -1.6261  -3.0098  
06:06:05	Alpha:
06:06:05		-1.4855   1.0768  
06:06:05	Class weight:
06:06:05		 1.0049   0.9938  

------------------------------

06:06:13	Accuracy on test set with the parameters above: 0.751

