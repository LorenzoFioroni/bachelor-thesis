05:58:02	Optimizer: adam
05:58:02	Optimizer params: {'lr': 0.02}
05:58:02	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:58:02	nLayers: 1 - nEpochs: 40 - batchSize: 32
05:58:02	Cost: weighted fidelity
05:58:02	Seed: None

------------------------------

05:58:05	epoch	loss	accuracy
05:58:08	    0	0.452	   0.478
05:58:21	    1	0.253	   0.478
05:58:34	    2	0.185	   0.744
05:58:47	    3	0.181	   0.746
05:59:00	    4	0.176	   0.750
05:59:13	    5	0.174	   0.748
05:59:28	    6	0.172	   0.748
05:59:41	    7	0.171	   0.742
05:59:54	    8	0.169	   0.742
06:00:07	    9	0.168	   0.748
06:00:21	   10	0.167	   0.742
06:00:35	   11	0.166	   0.742
06:00:49	   12	0.165	   0.744
06:01:02	   13	0.165	   0.744
06:01:15	   14	0.164	   0.748
06:01:27	   15	0.164	   0.742
06:01:42	   16	0.164	   0.746
06:01:55	   17	0.164	   0.742
06:02:08	   18	0.163	   0.744
06:02:21	   19	0.163	   0.750
06:02:34	   20	0.163	   0.748
06:02:49	   21	0.163	   0.746
06:03:02	   22	0.163	   0.750
06:03:16	   23	0.163	   0.750
06:03:29	   24	0.163	   0.744
06:03:42	   25	0.163	   0.750
06:03:57	   26	0.163	   0.750
06:04:10	   27	0.163	   0.750
06:04:23	   28	0.163	   0.750
06:04:36	   29	0.163	   0.750
06:04:49	   30	0.163	   0.750
06:05:04	   31	0.163	   0.750
06:05:18	   32	0.163	   0.750
06:05:30	   33	0.163	   0.750
06:05:43	   34	0.163	   0.750
06:05:56	   35	0.163	   0.750
06:06:11	   36	0.163	   0.750
06:06:24	   37	0.163	   0.750
06:06:37	   38	0.163	   0.750
06:06:50	   39	0.163	   0.750
06:07:03	   40	0.163	   0.750

------------------------------

06:07:05	Parameters at epoch 40:

06:07:05	Theta:
06:07:05		-0.0000   1.6179   1.6633  
06:07:05	Alpha:
06:07:05		 0.6302  -1.1120  
06:07:05	Class weight:
06:07:05		 1.0116   0.9883  

------------------------------

06:07:15	Accuracy on test set with the parameters above: 0.7376666666666667

