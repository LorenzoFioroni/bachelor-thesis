05:57:56	Optimizer: adam
05:57:56	Optimizer params: {'lr': 0.02}
05:57:56	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:57:56	nLayers: 1 - nEpochs: 40 - batchSize: 32
05:57:56	Cost: weighted fidelity
05:57:56	Seed: None

------------------------------

05:57:58	epoch	loss	accuracy
05:58:01	    0	0.308	   0.582
05:58:12	    1	0.231	   0.648
05:58:23	    2	0.203	   0.732
05:58:35	    3	0.190	   0.742
05:58:46	    4	0.184	   0.748
05:58:57	    5	0.180	   0.740
05:59:11	    6	0.177	   0.742
05:59:22	    7	0.176	   0.736
05:59:34	    8	0.176	   0.734
05:59:45	    9	0.175	   0.734
05:59:56	   10	0.175	   0.732
06:00:09	   11	0.175	   0.734
06:00:21	   12	0.175	   0.736
06:00:32	   13	0.175	   0.730
06:00:44	   14	0.175	   0.736
06:00:55	   15	0.175	   0.732
06:01:08	   16	0.175	   0.736
06:01:19	   17	0.175	   0.732
06:01:31	   18	0.175	   0.730
06:01:42	   19	0.175	   0.734
06:01:53	   20	0.175	   0.736
06:02:06	   21	0.175	   0.732
06:02:17	   22	0.175	   0.730
06:02:29	   23	0.175	   0.732
06:02:40	   24	0.175	   0.734
06:02:51	   25	0.175	   0.734
06:03:04	   26	0.175	   0.736
06:03:16	   27	0.175	   0.734
06:03:27	   28	0.175	   0.736
06:03:38	   29	0.175	   0.732
06:03:50	   30	0.175	   0.734
06:04:03	   31	0.175	   0.730
06:04:14	   32	0.175	   0.734
06:04:26	   33	0.175	   0.734
06:04:37	   34	0.175	   0.732
06:04:48	   35	0.175	   0.730
06:05:02	   36	0.175	   0.736
06:05:13	   37	0.175	   0.734
06:05:24	   38	0.175	   0.734
06:05:35	   39	0.175	   0.736
06:05:46	   40	0.175	   0.734

------------------------------

06:05:48	Parameters at epoch 40:

06:05:48	Theta:
06:05:48		 0.6684   1.4732  -1.3244  
06:05:48	Alpha:
06:05:48		-0.4392  -1.5275  
06:05:48	Class weight:
06:05:48		 0.9526   1.0603  

------------------------------

06:05:57	Accuracy on test set with the parameters above: 0.7473333333333333

