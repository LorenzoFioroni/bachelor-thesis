05:58:23	Optimizer: adam
05:58:23	Optimizer params: {'lr': 0.02}
05:58:23	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:58:23	nLayers: 1 - nEpochs: 40 - batchSize: 32
05:58:23	Cost: weighted fidelity
05:58:23	Seed: None

------------------------------

05:58:25	epoch	loss	accuracy
05:58:29	    0	0.423	   0.368
05:58:41	    1	0.313	   0.508
05:58:53	    2	0.274	   0.580
05:59:05	    3	0.229	   0.634
05:59:18	    4	0.196	   0.752
05:59:30	    5	0.183	   0.762
05:59:44	    6	0.176	   0.760
05:59:57	    7	0.172	   0.764
06:00:09	    8	0.169	   0.760
06:00:22	    9	0.167	   0.758
06:00:34	   10	0.166	   0.760
06:00:48	   11	0.165	   0.750
06:01:00	   12	0.165	   0.760
06:01:13	   13	0.164	   0.742
06:01:25	   14	0.164	   0.754
06:01:37	   15	0.164	   0.750
06:01:52	   16	0.164	   0.740
06:02:04	   17	0.164	   0.740
06:02:16	   18	0.164	   0.748
06:02:28	   19	0.164	   0.744
06:02:41	   20	0.164	   0.736
06:02:55	   21	0.164	   0.734
06:03:07	   22	0.164	   0.748
06:03:19	   23	0.164	   0.742
06:03:32	   24	0.164	   0.748
06:03:44	   25	0.164	   0.736
06:03:58	   26	0.164	   0.734
06:04:11	   27	0.164	   0.736
06:04:23	   28	0.164	   0.744
06:04:35	   29	0.164	   0.744
06:04:47	   30	0.164	   0.736
06:05:01	   31	0.164	   0.740
06:05:13	   32	0.164	   0.736
06:05:25	   33	0.164	   0.742
06:05:38	   34	0.164	   0.736
06:05:50	   35	0.164	   0.736
06:06:04	   36	0.164	   0.742
06:06:17	   37	0.164	   0.738
06:06:29	   38	0.164	   0.738
06:06:41	   39	0.164	   0.736
06:06:53	   40	0.164	   0.736

------------------------------

06:06:55	Parameters at epoch 40:

06:06:55	Theta:
06:06:55		 0.2974  -1.5137   0.1564  
06:06:55	Alpha:
06:06:55		-0.2386   1.2246  
06:06:55	Class weight:
06:06:55		 0.9704   1.0395  

------------------------------

06:07:04	Accuracy on test set with the parameters above: 0.7273333333333334

