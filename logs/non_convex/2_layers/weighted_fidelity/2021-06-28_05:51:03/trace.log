05:51:03	Optimizer: adam
05:51:03	Optimizer params: {'lr': 0.02}
05:51:03	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:51:03	nLayers: 2 - nEpochs: 40 - batchSize: 32
05:51:03	Cost: weighted fidelity
05:51:03	Seed: None

------------------------------

05:51:07	epoch	loss	accuracy
05:51:12	    0	0.268	   0.670
05:51:42	    1	0.193	   0.678
05:52:12	    2	0.164	   0.724
05:52:43	    3	0.159	   0.736
05:53:14	    4	0.158	   0.736
05:53:44	    5	0.157	   0.752
05:54:17	    6	0.157	   0.736
05:54:48	    7	0.157	   0.742
05:55:18	    8	0.157	   0.762
05:55:49	    9	0.157	   0.732
05:56:19	   10	0.156	   0.762
05:56:53	   11	0.156	   0.764
05:57:23	   12	0.157	   0.734
05:57:54	   13	0.156	   0.764
05:58:24	   14	0.157	   0.730
05:58:55	   15	0.156	   0.766
05:59:28	   16	0.156	   0.734
05:59:58	   17	0.156	   0.758
06:00:29	   18	0.156	   0.754
06:01:00	   19	0.156	   0.744
06:01:30	   20	0.156	   0.732
06:02:04	   21	0.156	   0.752
06:02:35	   22	0.156	   0.752
06:03:06	   23	0.156	   0.762
06:03:36	   24	0.156	   0.734
06:04:07	   25	0.156	   0.764
06:04:40	   26	0.156	   0.752
06:05:11	   27	0.156	   0.762
06:05:42	   28	0.156	   0.754
06:06:12	   29	0.156	   0.766
06:06:43	   30	0.156	   0.748
06:07:16	   31	0.156	   0.762
06:07:46	   32	0.156	   0.766
06:08:17	   33	0.156	   0.766
06:08:47	   34	0.156	   0.756
06:09:17	   35	0.156	   0.762
06:09:50	   36	0.156	   0.754
06:10:20	   37	0.155	   0.756
06:10:51	   38	0.155	   0.764
06:11:21	   39	0.155	   0.760
06:11:51	   40	0.155	   0.760

------------------------------

06:11:54	Parameters at epoch 40:

06:11:54	Theta:
06:11:54		-1.1711   1.7921   0.0597  
06:11:54		 0.1970  -0.1762   0.8371  
06:11:54	Alpha:
06:11:54		 1.6054  -0.3380  
06:11:54		-1.2269  -1.4484  
06:11:54	Class weight:
06:11:54		 1.0312   1.0119  

------------------------------

06:12:09	Accuracy on test set with the parameters above: 0.758

