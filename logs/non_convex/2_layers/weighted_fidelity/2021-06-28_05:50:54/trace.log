05:50:54	Optimizer: adam
05:50:54	Optimizer params: {'lr': 0.02}
05:50:54	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:50:54	nLayers: 2 - nEpochs: 40 - batchSize: 32
05:50:54	Cost: weighted fidelity
05:50:54	Seed: None

------------------------------

05:50:58	epoch	loss	accuracy
05:51:02	    0	0.349	   0.510
05:51:25	    1	0.206	   0.708
05:51:48	    2	0.165	   0.750
05:52:11	    3	0.158	   0.764
05:52:34	    4	0.155	   0.752
05:52:57	    5	0.152	   0.756
05:53:22	    6	0.151	   0.756
05:53:45	    7	0.150	   0.756
05:54:09	    8	0.150	   0.760
05:54:31	    9	0.149	   0.764
05:54:55	   10	0.149	   0.764
05:55:20	   11	0.149	   0.766
05:55:43	   12	0.149	   0.760
05:56:06	   13	0.149	   0.760
05:56:29	   14	0.149	   0.756
05:56:52	   15	0.149	   0.764
05:57:17	   16	0.148	   0.766
05:57:40	   17	0.149	   0.760
05:58:03	   18	0.149	   0.762
05:58:26	   19	0.148	   0.768
05:58:48	   20	0.148	   0.766
05:59:13	   21	0.148	   0.768
05:59:35	   22	0.148	   0.768
05:59:58	   23	0.148	   0.770
06:00:20	   24	0.148	   0.768
06:00:43	   25	0.148	   0.770
06:01:07	   26	0.148	   0.764
06:01:30	   27	0.148	   0.762
06:01:52	   28	0.148	   0.766
06:02:15	   29	0.148	   0.768
06:02:37	   30	0.148	   0.764
06:03:01	   31	0.148	   0.766
06:03:24	   32	0.148	   0.766
06:03:46	   33	0.148	   0.766
06:04:09	   34	0.148	   0.768
06:04:31	   35	0.148	   0.768
06:04:56	   36	0.148	   0.766
06:05:19	   37	0.148	   0.766
06:05:42	   38	0.148	   0.768
06:06:04	   39	0.148	   0.766
06:06:27	   40	0.148	   0.770

------------------------------

06:06:29	Parameters at epoch 40:

06:06:29	Theta:
06:06:29		 1.0343  -0.5781   0.8476  
06:06:29		 1.0716   1.2153  -0.5415  
06:06:29	Alpha:
06:06:29		 0.2324   1.3034  
06:06:29		-0.9687  -0.3218  
06:06:29	Class weight:
06:06:29		 0.9891   1.0390  

------------------------------

06:06:41	Accuracy on test set with the parameters above: 0.755

