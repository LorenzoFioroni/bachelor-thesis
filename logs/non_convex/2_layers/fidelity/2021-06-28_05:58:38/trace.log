05:58:38	Optimizer: adam
05:58:38	Optimizer params: {'lr': 0.02}
05:58:38	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:58:38	nLayers: 2 - nEpochs: 40 - batchSize: 32
05:58:38	Cost: fidelity
05:58:38	Seed: None

------------------------------

05:58:41	epoch	loss	accuracy
05:58:44	    0	0.466	   0.626
05:58:56	    1	0.365	   0.762
05:59:09	    2	0.306	   0.768
05:59:21	    3	0.273	   0.772
05:59:34	    4	0.266	   0.770
05:59:46	    5	0.265	   0.768
06:00:00	    6	0.263	   0.772
06:00:13	    7	0.263	   0.772
06:00:25	    8	0.263	   0.764
06:00:38	    9	0.262	   0.770
06:00:50	   10	0.262	   0.768
06:01:04	   11	0.262	   0.770
06:01:17	   12	0.261	   0.766
06:01:29	   13	0.261	   0.770
06:01:41	   14	0.260	   0.766
06:01:54	   15	0.260	   0.768
06:02:08	   16	0.259	   0.768
06:02:20	   17	0.258	   0.768
06:02:33	   18	0.258	   0.768
06:02:45	   19	0.257	   0.770
06:02:58	   20	0.256	   0.772
06:03:12	   21	0.255	   0.770
06:03:25	   22	0.254	   0.770
06:03:37	   23	0.253	   0.764
06:03:49	   24	0.252	   0.770
06:04:02	   25	0.251	   0.772
06:04:16	   26	0.250	   0.772
06:04:29	   27	0.250	   0.772
06:04:41	   28	0.249	   0.772
06:04:54	   29	0.248	   0.772
06:05:06	   30	0.247	   0.772
06:05:21	   31	0.247	   0.772
06:05:33	   32	0.246	   0.772
06:05:45	   33	0.246	   0.772
06:05:57	   34	0.245	   0.772
06:06:10	   35	0.244	   0.772
06:06:24	   36	0.244	   0.772
06:06:37	   37	0.243	   0.772
06:06:49	   38	0.243	   0.772
06:07:01	   39	0.243	   0.772
06:07:13	   40	0.242	   0.772

------------------------------

06:07:16	Parameters at epoch 40:

06:07:16	Theta:
06:07:16		-0.5315   0.0338  -0.6274  
06:07:16		 2.1578   1.6025  -1.3390  
06:07:16	Alpha:
06:07:16		 0.6527  -2.0111  
06:07:16		 0.0210   4.0533  

------------------------------

06:07:28	Accuracy on test set with the parameters above: 0.7446666666666667

