05:58:27	Optimizer: adam
05:58:27	Optimizer params: {'lr': 0.02}
05:58:27	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:58:27	nLayers: 2 - nEpochs: 40 - batchSize: 32
05:58:27	Cost: fidelity
05:58:27	Seed: None

------------------------------

05:58:30	epoch	loss	accuracy
05:58:33	    0	0.482	   0.528
05:58:45	    1	0.348	   0.722
05:58:57	    2	0.285	   0.768
05:59:09	    3	0.276	   0.760
05:59:21	    4	0.274	   0.760
05:59:33	    5	0.273	   0.768
05:59:47	    6	0.273	   0.770
05:59:59	    7	0.273	   0.770
06:00:11	    8	0.272	   0.774
06:00:24	    9	0.272	   0.776
06:00:36	   10	0.272	   0.774
06:00:50	   11	0.272	   0.774
06:01:02	   12	0.272	   0.772
06:01:14	   13	0.272	   0.768
06:01:26	   14	0.272	   0.776
06:01:38	   15	0.272	   0.768
06:01:52	   16	0.272	   0.774
06:02:04	   17	0.272	   0.778
06:02:16	   18	0.272	   0.774
06:02:28	   19	0.272	   0.768
06:02:40	   20	0.272	   0.770
06:02:55	   21	0.272	   0.766
06:03:07	   22	0.272	   0.776
06:03:19	   23	0.272	   0.776
06:03:31	   24	0.272	   0.776
06:03:43	   25	0.272	   0.768
06:03:58	   26	0.272	   0.768
06:04:10	   27	0.272	   0.776
06:04:22	   28	0.272	   0.772
06:04:34	   29	0.272	   0.772
06:04:46	   30	0.272	   0.772
06:05:00	   31	0.272	   0.776
06:05:13	   32	0.272	   0.776
06:05:25	   33	0.272	   0.776
06:05:37	   34	0.272	   0.774
06:05:49	   35	0.272	   0.772
06:06:03	   36	0.272	   0.772
06:06:16	   37	0.272	   0.776
06:06:28	   38	0.272	   0.772
06:06:40	   39	0.272	   0.772
06:06:52	   40	0.272	   0.776

------------------------------

06:06:55	Parameters at epoch 40:

06:06:55	Theta:
06:06:55		-0.1884   1.7055  -1.0610  
06:06:55		 0.1028  -0.2364   0.2284  
06:06:55	Alpha:
06:06:55		-0.1910  -2.0862  
06:06:55		 0.1285  -0.0078  

------------------------------

06:07:06	Accuracy on test set with the parameters above: 0.7343333333333333

