05:58:36	Optimizer: adam
05:58:36	Optimizer params: {'lr': 0.02}
05:58:36	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:58:36	nLayers: 2 - nEpochs: 40 - batchSize: 32
05:58:36	Cost: fidelity
05:58:36	Seed: None

------------------------------

05:58:39	epoch	loss	accuracy
05:58:42	    0	0.422	   0.762
05:58:54	    1	0.348	   0.774
05:59:06	    2	0.293	   0.756
05:59:19	    3	0.277	   0.768
05:59:31	    4	0.275	   0.764
05:59:44	    5	0.274	   0.762
05:59:59	    6	0.274	   0.764
06:00:11	    7	0.273	   0.762
06:00:24	    8	0.273	   0.762
06:00:37	    9	0.273	   0.762
06:00:49	   10	0.273	   0.762
06:01:05	   11	0.273	   0.762
06:01:18	   12	0.273	   0.762
06:01:31	   13	0.273	   0.762
06:01:43	   14	0.273	   0.762
06:01:56	   15	0.273	   0.762
06:02:11	   16	0.273	   0.762
06:02:24	   17	0.273	   0.762
06:02:37	   18	0.273	   0.762
06:02:50	   19	0.273	   0.762
06:03:02	   20	0.273	   0.762
06:03:18	   21	0.273	   0.762
06:03:30	   22	0.273	   0.762
06:03:43	   23	0.273	   0.762
06:03:56	   24	0.273	   0.762
06:04:08	   25	0.273	   0.762
06:04:23	   26	0.273	   0.762
06:04:36	   27	0.273	   0.762
06:04:49	   28	0.273	   0.762
06:05:01	   29	0.273	   0.762
06:05:14	   30	0.273	   0.762
06:05:29	   31	0.273	   0.762
06:05:42	   32	0.273	   0.762
06:05:54	   33	0.273	   0.762
06:06:07	   34	0.273	   0.762
06:06:20	   35	0.273	   0.762
06:06:35	   36	0.273	   0.762
06:06:48	   37	0.273	   0.762
06:07:01	   38	0.273	   0.762
06:07:13	   39	0.273	   0.762
06:07:26	   40	0.273	   0.762

------------------------------

06:07:29	Parameters at epoch 40:

06:07:29	Theta:
06:07:29		-1.1218  -0.0114  -1.8157  
06:07:29		-0.1043   1.5998  -0.7994  
06:07:29	Alpha:
06:07:29		-0.5544   0.7463  
06:07:29		 0.0395  -1.4225  

------------------------------

06:07:41	Accuracy on test set with the parameters above: 0.7456666666666667

