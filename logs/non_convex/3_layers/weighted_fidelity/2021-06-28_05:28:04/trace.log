05:28:04	Optimizer: adam
05:28:04	Optimizer params: {'lr': 0.02}
05:28:04	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:28:04	nLayers: 3 - nEpochs: 40 - batchSize: 32
05:28:04	Cost: weighted fidelity
05:28:04	Seed: None

------------------------------

05:28:08	epoch	loss	accuracy
05:28:13	    0	0.574	   0.264
05:28:46	    1	0.238	   0.682
05:29:19	    2	0.174	   0.752
05:29:53	    3	0.166	   0.762
05:30:27	    4	0.161	   0.768
05:31:01	    5	0.159	   0.760
05:31:37	    6	0.159	   0.772
05:32:11	    7	0.158	   0.770
05:32:44	    8	0.158	   0.776
05:33:18	    9	0.158	   0.776
05:33:51	   10	0.158	   0.766
05:34:27	   11	0.158	   0.774
05:35:01	   12	0.157	   0.776
05:35:35	   13	0.157	   0.774
05:36:09	   14	0.157	   0.774
05:36:42	   15	0.157	   0.772
05:37:18	   16	0.157	   0.776
05:37:52	   17	0.157	   0.780
05:38:26	   18	0.157	   0.770
05:38:59	   19	0.157	   0.780
05:39:33	   20	0.157	   0.772
05:40:09	   21	0.157	   0.772
05:40:43	   22	0.157	   0.776
05:41:17	   23	0.157	   0.772
05:41:51	   24	0.157	   0.778
05:42:24	   25	0.156	   0.778
05:43:01	   26	0.156	   0.778
05:43:34	   27	0.156	   0.774
05:44:08	   28	0.156	   0.770
05:44:41	   29	0.156	   0.780
05:45:15	   30	0.156	   0.782
05:45:52	   31	0.156	   0.778
05:46:26	   32	0.156	   0.780
05:47:00	   33	0.156	   0.774
05:47:33	   34	0.156	   0.780
05:48:07	   35	0.156	   0.778
05:48:43	   36	0.156	   0.780
05:49:17	   37	0.156	   0.776
05:49:50	   38	0.156	   0.778
05:50:24	   39	0.156	   0.778
05:50:57	   40	0.156	   0.776

------------------------------

05:51:00	Parameters at epoch 40:

05:51:00	Theta:
05:51:00		 1.7315  -1.1181   0.5807  
05:51:00		 0.9009  -1.6205  -1.3101  
05:51:00		 1.2872  -2.9542  -0.4002  
05:51:00	Alpha:
05:51:00		 1.3989   0.6814  
05:51:00		-0.2648   0.0475  
05:51:00		 0.8219  -0.5772  
05:51:00	Class weight:
05:51:00		 1.0011   1.0223  

------------------------------

05:51:14	Accuracy on test set with the parameters above: 0.758

