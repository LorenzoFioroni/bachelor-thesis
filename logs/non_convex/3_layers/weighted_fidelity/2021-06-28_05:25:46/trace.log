05:25:46	Optimizer: adam
05:25:46	Optimizer params: {'lr': 0.02}
05:25:46	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:25:46	nLayers: 3 - nEpochs: 40 - batchSize: 32
05:25:46	Cost: weighted fidelity
05:25:46	Seed: None

------------------------------

05:25:50	epoch	loss	accuracy
05:25:55	    0	0.412	   0.442
05:26:31	    1	0.218	   0.618
05:27:07	    2	0.178	   0.732
05:27:42	    3	0.167	   0.726
05:28:18	    4	0.165	   0.738
05:28:54	    5	0.164	   0.740
05:29:33	    6	0.163	   0.740
05:30:09	    7	0.163	   0.736
05:30:45	    8	0.162	   0.738
05:31:21	    9	0.161	   0.742
05:31:57	   10	0.161	   0.740
05:32:36	   11	0.160	   0.738
05:33:12	   12	0.160	   0.742
05:33:49	   13	0.160	   0.744
05:34:25	   14	0.159	   0.738
05:35:01	   15	0.159	   0.744
05:35:40	   16	0.159	   0.746
05:36:16	   17	0.158	   0.748
05:36:52	   18	0.158	   0.742
05:37:29	   19	0.158	   0.744
05:38:04	   20	0.158	   0.748
05:38:43	   21	0.157	   0.750
05:39:20	   22	0.157	   0.746
05:39:56	   23	0.157	   0.748
05:40:32	   24	0.157	   0.748
05:41:08	   25	0.157	   0.752
05:41:47	   26	0.157	   0.748
05:42:23	   27	0.156	   0.752
05:43:00	   28	0.156	   0.750
05:43:35	   29	0.156	   0.748
05:44:11	   30	0.156	   0.750
05:44:50	   31	0.156	   0.750
05:45:26	   32	0.156	   0.750
05:46:02	   33	0.156	   0.752
05:46:38	   34	0.155	   0.754
05:47:14	   35	0.155	   0.752
05:47:53	   36	0.155	   0.754
05:48:29	   37	0.155	   0.750
05:49:05	   38	0.155	   0.752
05:49:41	   39	0.155	   0.754
05:50:18	   40	0.155	   0.750

------------------------------

05:50:20	Parameters at epoch 40:

05:50:20	Theta:
05:50:20		-0.4452  -2.5820   0.8166  
05:50:20		-1.1947   1.0797  -1.3183  
05:50:20		-0.0814   0.0773  -0.2227  
05:50:20	Alpha:
05:50:20		 3.1150   1.8981  
05:50:20		 1.0951  -0.7981  
05:50:20		-0.0030   0.2049  
05:50:20	Class weight:
05:50:20		 1.0458   1.0018  

------------------------------

05:50:35	Accuracy on test set with the parameters above: 0.7593333333333333

