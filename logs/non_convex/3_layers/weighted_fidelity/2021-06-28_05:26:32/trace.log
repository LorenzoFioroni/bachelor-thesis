05:26:32	Optimizer: adam
05:26:32	Optimizer params: {'lr': 0.02}
05:26:32	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:26:32	nLayers: 3 - nEpochs: 40 - batchSize: 32
05:26:32	Cost: weighted fidelity
05:26:32	Seed: None

------------------------------

05:26:34	epoch	loss	accuracy
05:26:40	    0	0.405	   0.324
05:27:12	    1	0.196	   0.724
05:27:45	    2	0.167	   0.768
05:28:18	    3	0.159	   0.762
05:28:50	    4	0.155	   0.782
05:29:23	    5	0.153	   0.786
05:29:59	    6	0.153	   0.790
05:30:31	    7	0.152	   0.788
05:31:04	    8	0.151	   0.788
05:31:37	    9	0.151	   0.796
05:32:10	   10	0.151	   0.790
05:32:45	   11	0.151	   0.792
05:33:18	   12	0.151	   0.790
05:33:51	   13	0.151	   0.798
05:34:24	   14	0.151	   0.796
05:34:56	   15	0.151	   0.796
05:35:32	   16	0.151	   0.804
05:36:05	   17	0.151	   0.796
05:36:38	   18	0.150	   0.800
05:37:11	   19	0.150	   0.802
05:37:44	   20	0.150	   0.794
05:38:19	   21	0.150	   0.800
05:38:52	   22	0.150	   0.796
05:39:25	   23	0.150	   0.798
05:39:59	   24	0.151	   0.796
05:40:31	   25	0.150	   0.800
05:41:07	   26	0.150	   0.804
05:41:40	   27	0.150	   0.800
05:42:13	   28	0.150	   0.800
05:42:46	   29	0.150	   0.806
05:43:19	   30	0.150	   0.798
05:43:55	   31	0.150	   0.804
05:44:28	   32	0.150	   0.800
05:45:01	   33	0.150	   0.808
05:45:34	   34	0.150	   0.800
05:46:07	   35	0.150	   0.808
05:46:43	   36	0.150	   0.806
05:47:16	   37	0.150	   0.810
05:47:48	   38	0.149	   0.804
05:48:21	   39	0.149	   0.810
05:48:55	   40	0.149	   0.804

------------------------------

05:48:57	Parameters at epoch 40:

05:48:57	Theta:
05:48:57		-1.8629   1.9122   0.2940  
05:48:57		-2.4275   0.1706  -0.9426  
05:48:57		 0.7766  -2.9532   1.7007  
05:48:57	Alpha:
05:48:57		 0.9363   0.3152  
05:48:57		 1.1156   0.0276  
05:48:57		 0.3049  -1.7913  
05:48:57	Class weight:
05:48:57		 1.0106   1.0466  

------------------------------

05:49:11	Accuracy on test set with the parameters above: 0.7836666666666666

