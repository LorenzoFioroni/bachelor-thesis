05:57:10	Optimizer: adam
05:57:10	Optimizer params: {'lr': 0.02}
05:57:10	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:57:10	nLayers: 3 - nEpochs: 40 - batchSize: 32
05:57:10	Cost: fidelity
05:57:10	Seed: None

------------------------------

05:57:13	epoch	loss	accuracy
05:57:18	    0	0.566	   0.300
05:57:37	    1	0.372	   0.736
05:57:56	    2	0.302	   0.724
05:58:16	    3	0.297	   0.724
05:58:35	    4	0.296	   0.736
05:58:54	    5	0.295	   0.722
05:59:16	    6	0.295	   0.738
05:59:35	    7	0.294	   0.732
05:59:55	    8	0.294	   0.734
06:00:14	    9	0.293	   0.734
06:00:34	   10	0.293	   0.738
06:00:57	   11	0.292	   0.736
06:01:17	   12	0.292	   0.734
06:01:36	   13	0.291	   0.734
06:01:56	   14	0.291	   0.734
06:02:15	   15	0.291	   0.736
06:02:37	   16	0.290	   0.740
06:02:56	   17	0.290	   0.742
06:03:16	   18	0.289	   0.742
06:03:35	   19	0.289	   0.742
06:03:54	   20	0.289	   0.738
06:04:17	   21	0.289	   0.736
06:04:36	   22	0.288	   0.740
06:04:55	   23	0.288	   0.736
06:05:15	   24	0.288	   0.740
06:05:35	   25	0.288	   0.746
06:05:57	   26	0.287	   0.746
06:06:17	   27	0.287	   0.736
06:06:36	   28	0.287	   0.740
06:06:56	   29	0.287	   0.740
06:07:15	   30	0.287	   0.742
06:07:37	   31	0.287	   0.742
06:07:57	   32	0.287	   0.744
06:08:16	   33	0.287	   0.744
06:08:36	   34	0.286	   0.742
06:08:55	   35	0.286	   0.738
06:09:18	   36	0.286	   0.744
06:09:37	   37	0.286	   0.750
06:09:56	   38	0.286	   0.748
06:10:16	   39	0.286	   0.750
06:10:35	   40	0.286	   0.750

------------------------------

06:10:38	Parameters at epoch 40:

06:10:38	Theta:
06:10:38		-0.2336   0.0051   0.0967  
06:10:38		-0.9784   0.9589   0.2496  
06:10:38		 0.9707   1.2060  -0.0382  
06:10:38	Alpha:
06:10:38		-1.0282  -0.7316  
06:10:38		-2.1993  -1.6581  
06:10:38		 1.0366   0.1979  

------------------------------

06:10:53	Accuracy on test set with the parameters above: 0.7616666666666667

