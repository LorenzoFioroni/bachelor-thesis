05:57:46	Optimizer: adam
05:57:46	Optimizer params: {'lr': 0.02}
05:57:46	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:57:46	nLayers: 3 - nEpochs: 40 - batchSize: 32
05:57:46	Cost: fidelity
05:57:46	Seed: None

------------------------------

05:57:50	epoch	loss	accuracy
05:57:53	    0	0.381	   0.686
05:58:13	    1	0.317	   0.712
05:58:32	    2	0.308	   0.702
05:58:51	    3	0.306	   0.706
05:59:09	    4	0.306	   0.710
05:59:28	    5	0.305	   0.718
05:59:50	    6	0.305	   0.718
06:00:09	    7	0.305	   0.722
06:00:28	    8	0.304	   0.716
06:00:47	    9	0.304	   0.720
06:01:05	   10	0.304	   0.716
06:01:27	   11	0.303	   0.720
06:01:46	   12	0.303	   0.718
06:02:05	   13	0.303	   0.720
06:02:23	   14	0.303	   0.722
06:02:42	   15	0.303	   0.722
06:03:04	   16	0.303	   0.722
06:03:23	   17	0.303	   0.724
06:03:42	   18	0.303	   0.720
06:04:00	   19	0.302	   0.722
06:04:19	   20	0.302	   0.728
06:04:40	   21	0.302	   0.724
06:04:59	   22	0.302	   0.722
06:05:18	   23	0.302	   0.720
06:05:37	   24	0.302	   0.724
06:05:57	   25	0.302	   0.724
06:06:19	   26	0.302	   0.722
06:06:38	   27	0.302	   0.724
06:06:56	   28	0.302	   0.722
06:07:15	   29	0.301	   0.722
06:07:34	   30	0.301	   0.722
06:07:55	   31	0.301	   0.720
06:08:14	   32	0.301	   0.724
06:08:33	   33	0.301	   0.724
06:08:52	   34	0.301	   0.720
06:09:11	   35	0.301	   0.720
06:09:32	   36	0.301	   0.722
06:09:51	   37	0.301	   0.722
06:10:10	   38	0.301	   0.722
06:10:28	   39	0.301	   0.722
06:10:47	   40	0.300	   0.722

------------------------------

06:10:50	Parameters at epoch 40:

06:10:50	Theta:
06:10:50		 0.9826  -0.5838   0.3528  
06:10:50		-0.0770  -0.9127  -0.2047  
06:10:50		-1.3964   1.0829   1.4222  
06:10:50	Alpha:
06:10:50		 1.6583  -1.3755  
06:10:50		 0.0729   1.6971  
06:10:50		 0.4595   1.0158  

------------------------------

06:11:04	Accuracy on test set with the parameters above: 0.7356666666666667

