05:57:54	Optimizer: adam
05:57:54	Optimizer params: {'lr': 0.02}
05:57:54	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:57:54	nLayers: 3 - nEpochs: 40 - batchSize: 32
05:57:54	Cost: fidelity
05:57:54	Seed: None

------------------------------

05:57:58	epoch	loss	accuracy
05:58:01	    0	0.384	   0.642
05:58:21	    1	0.297	   0.734
05:58:40	    2	0.291	   0.738
05:58:59	    3	0.289	   0.734
05:59:19	    4	0.288	   0.730
05:59:38	    5	0.287	   0.736
06:00:00	    6	0.285	   0.738
06:00:20	    7	0.283	   0.744
06:00:40	    8	0.280	   0.754
06:00:59	    9	0.279	   0.754
06:01:19	   10	0.278	   0.762
06:01:41	   11	0.277	   0.764
06:02:01	   12	0.277	   0.782
06:02:20	   13	0.277	   0.774
06:02:39	   14	0.276	   0.770
06:02:58	   15	0.276	   0.776
06:03:21	   16	0.276	   0.802
06:03:40	   17	0.276	   0.790
06:04:00	   18	0.276	   0.784
06:04:19	   19	0.276	   0.786
06:04:38	   20	0.276	   0.786
06:05:00	   21	0.276	   0.788
06:05:20	   22	0.276	   0.788
06:05:39	   23	0.276	   0.794
06:05:59	   24	0.276	   0.780
06:06:18	   25	0.275	   0.790
06:06:40	   26	0.275	   0.800
06:07:00	   27	0.275	   0.778
06:07:20	   28	0.275	   0.792
06:07:39	   29	0.275	   0.794
06:07:58	   30	0.275	   0.794
06:08:21	   31	0.275	   0.796
06:08:40	   32	0.275	   0.790
06:09:00	   33	0.274	   0.794
06:09:19	   34	0.274	   0.790
06:09:38	   35	0.274	   0.794
06:10:01	   36	0.274	   0.790
06:10:20	   37	0.273	   0.788
06:10:40	   38	0.273	   0.796
06:10:59	   39	0.272	   0.792
06:11:19	   40	0.272	   0.796

------------------------------

06:11:22	Parameters at epoch 40:

06:11:22	Theta:
06:11:22		 0.9208   0.2088  -1.0575  
06:11:22		-1.4467  -1.0933   1.3101  
06:11:22		 0.1984  -1.4954  -1.0207  
06:11:22	Alpha:
06:11:22		-0.7469   0.6471  
06:11:22		-2.9361   1.6161  
06:11:22		 1.1163   0.0157  

------------------------------

06:11:36	Accuracy on test set with the parameters above: 0.7906666666666666

