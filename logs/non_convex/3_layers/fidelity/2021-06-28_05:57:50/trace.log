05:57:50	Optimizer: adam
05:57:50	Optimizer params: {'lr': 0.02}
05:57:50	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:57:50	nLayers: 3 - nEpochs: 40 - batchSize: 32
05:57:50	Cost: fidelity
05:57:50	Seed: None

------------------------------

05:57:54	epoch	loss	accuracy
05:57:57	    0	0.525	   0.490
05:58:17	    1	0.385	   0.652
05:58:36	    2	0.297	   0.728
05:58:56	    3	0.290	   0.726
05:59:15	    4	0.289	   0.730
05:59:34	    5	0.287	   0.726
05:59:57	    6	0.287	   0.724
06:00:16	    7	0.287	   0.722
06:00:35	    8	0.287	   0.728
06:00:55	    9	0.287	   0.722
06:01:14	   10	0.287	   0.730
06:01:36	   11	0.287	   0.724
06:01:56	   12	0.287	   0.728
06:02:15	   13	0.287	   0.728
06:02:34	   14	0.287	   0.728
06:02:54	   15	0.287	   0.718
06:03:16	   16	0.287	   0.726
06:03:35	   17	0.287	   0.718
06:03:55	   18	0.287	   0.720
06:04:14	   19	0.287	   0.728
06:04:33	   20	0.287	   0.728
06:04:56	   21	0.287	   0.722
06:05:16	   22	0.287	   0.722
06:05:35	   23	0.287	   0.728
06:05:55	   24	0.287	   0.724
06:06:14	   25	0.287	   0.724
06:06:36	   26	0.287	   0.726
06:06:56	   27	0.287	   0.728
06:07:15	   28	0.287	   0.722
06:07:34	   29	0.287	   0.726
06:07:53	   30	0.287	   0.726
06:08:16	   31	0.287	   0.728
06:08:35	   32	0.287	   0.724
06:08:55	   33	0.287	   0.724
06:09:14	   34	0.287	   0.728
06:09:33	   35	0.287	   0.726
06:09:55	   36	0.287	   0.722
06:10:15	   37	0.287	   0.728
06:10:35	   38	0.287	   0.728
06:10:54	   39	0.287	   0.724
06:11:14	   40	0.287	   0.724

------------------------------

06:11:17	Parameters at epoch 40:

06:11:17	Theta:
06:11:17		-0.1226  -0.4238  -0.3674  
06:11:17		 0.8361   0.1305  -0.4369  
06:11:17		 0.0407   1.8226  -1.0091  
06:11:17	Alpha:
06:11:17		-0.6940  -1.1609  
06:11:17		 0.2541  -0.3138  
06:11:17		-0.2186  -0.5715  

------------------------------

06:11:31	Accuracy on test set with the parameters above: 0.7343333333333333

