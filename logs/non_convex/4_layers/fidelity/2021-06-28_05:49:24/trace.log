05:49:24	Optimizer: adam
05:49:24	Optimizer params: {'lr': 0.02}
05:49:24	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:49:24	nLayers: 4 - nEpochs: 40 - batchSize: 32
05:49:24	Cost: fidelity
05:49:24	Seed: None

------------------------------

05:49:29	epoch	loss	accuracy
05:49:33	    0	0.618	   0.340
05:50:01	    1	0.445	   0.534
05:50:29	    2	0.309	   0.748
05:50:57	    3	0.283	   0.780
05:51:24	    4	0.272	   0.776
05:51:52	    5	0.268	   0.776
05:52:23	    6	0.266	   0.770
05:52:51	    7	0.265	   0.782
05:53:19	    8	0.263	   0.770
05:53:47	    9	0.262	   0.774
05:54:15	   10	0.261	   0.772
05:54:46	   11	0.261	   0.778
05:55:13	   12	0.260	   0.776
05:55:40	   13	0.260	   0.778
05:56:09	   14	0.260	   0.776
05:56:36	   15	0.260	   0.776
05:57:08	   16	0.260	   0.790
05:57:36	   17	0.260	   0.780
05:58:04	   18	0.260	   0.782
05:58:32	   19	0.260	   0.784
05:59:00	   20	0.260	   0.778
05:59:32	   21	0.260	   0.784
06:00:00	   22	0.260	   0.784
06:00:28	   23	0.260	   0.784
06:00:55	   24	0.260	   0.786
06:01:24	   25	0.260	   0.782
06:01:55	   26	0.260	   0.786
06:02:22	   27	0.260	   0.782
06:02:50	   28	0.259	   0.786
06:03:18	   29	0.259	   0.784
06:03:47	   30	0.259	   0.786
06:04:17	   31	0.259	   0.784
06:04:45	   32	0.259	   0.786
06:05:13	   33	0.259	   0.788
06:05:40	   34	0.259	   0.786
06:06:08	   35	0.259	   0.790
06:06:40	   36	0.259	   0.788
06:07:08	   37	0.259	   0.784
06:07:37	   38	0.259	   0.788
06:08:04	   39	0.259	   0.788
06:08:32	   40	0.259	   0.790

------------------------------

06:08:36	Parameters at epoch 40:

06:08:36	Theta:
06:08:36		-1.3431  -0.0586   0.2290  
06:08:36		-0.2211  -0.4972  -1.0957  
06:08:36		 1.8244  -1.0510  -1.1081  
06:08:36		-1.0695   0.4802  -0.1951  
06:08:36	Alpha:
06:08:36		-0.2344   0.8735  
06:08:36		-0.9995   0.8993  
06:08:36		 0.6176  -0.7826  
06:08:36		 0.4394   0.5349  

------------------------------

06:08:53	Accuracy on test set with the parameters above: 0.7636666666666667

