05:36:13	Optimizer: adam
05:36:13	Optimizer params: {'lr': 0.02}
05:36:13	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
05:36:13	nLayers: 4 - nEpochs: 40 - batchSize: 32
05:36:13	Cost: fidelity
05:36:13	Seed: None

------------------------------

05:36:17	epoch	loss	accuracy
05:36:23	    0	0.597	   0.224
05:36:50	    1	0.316	   0.752
05:37:19	    2	0.304	   0.746
05:37:46	    3	0.288	   0.748
05:38:13	    4	0.286	   0.750
05:38:41	    5	0.283	   0.754
05:39:12	    6	0.283	   0.746
05:39:40	    7	0.282	   0.750
05:40:08	    8	0.281	   0.748
05:40:36	    9	0.281	   0.752
05:41:04	   10	0.280	   0.748
05:41:35	   11	0.280	   0.746
05:42:03	   12	0.279	   0.748
05:42:32	   13	0.279	   0.746
05:43:00	   14	0.279	   0.748
05:43:28	   15	0.278	   0.746
05:43:59	   16	0.278	   0.750
05:44:27	   17	0.278	   0.746
05:44:55	   18	0.277	   0.748
05:45:24	   19	0.277	   0.752
05:45:52	   20	0.276	   0.750
05:46:23	   21	0.276	   0.750
05:46:51	   22	0.276	   0.752
05:47:18	   23	0.275	   0.754
05:47:47	   24	0.275	   0.750
05:48:15	   25	0.274	   0.754
05:48:45	   26	0.274	   0.750
05:49:14	   27	0.273	   0.752
05:49:42	   28	0.272	   0.754
05:50:10	   29	0.272	   0.754
05:50:38	   30	0.271	   0.754
05:51:09	   31	0.271	   0.756
05:51:37	   32	0.270	   0.748
05:52:05	   33	0.270	   0.756
05:52:32	   34	0.269	   0.752
05:53:01	   35	0.269	   0.752
05:53:32	   36	0.268	   0.746
05:54:00	   37	0.268	   0.752
05:54:29	   38	0.267	   0.748
05:54:57	   39	0.267	   0.746
05:55:25	   40	0.266	   0.748

------------------------------

05:55:29	Parameters at epoch 40:

05:55:29	Theta:
05:55:29		 0.3652   0.2930  -1.6512  
05:55:29		 0.7188   0.3106   0.1332  
05:55:29		-1.6741  -1.2189  -0.3281  
05:55:29		-2.3351   0.8480   0.7509  
05:55:29	Alpha:
05:55:29		 0.5027  -1.1236  
05:55:29		 0.2095   1.9060  
05:55:29		 0.1050   2.0473  
05:55:29		 0.4010   0.2479  

------------------------------

05:55:46	Accuracy on test set with the parameters above: 0.74

