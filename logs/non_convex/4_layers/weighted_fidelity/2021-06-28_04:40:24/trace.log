04:40:24	Optimizer: adam
04:40:24	Optimizer params: {'lr': 0.02}
04:40:24	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
04:40:24	nLayers: 4 - nEpochs: 40 - batchSize: 32
04:40:24	Cost: weighted fidelity
04:40:24	Seed: None

------------------------------

04:40:29	epoch	loss	accuracy
04:40:35	    0	0.248	   0.592
04:41:26	    1	0.189	   0.734
04:42:18	    2	0.173	   0.732
04:43:11	    3	0.168	   0.742
04:44:03	    4	0.167	   0.744
04:44:55	    5	0.165	   0.752
04:45:51	    6	0.165	   0.752
04:46:43	    7	0.164	   0.748
04:47:35	    8	0.164	   0.752
04:48:28	    9	0.164	   0.754
04:49:21	   10	0.163	   0.750
04:50:16	   11	0.163	   0.748
04:51:09	   12	0.163	   0.756
04:52:02	   13	0.163	   0.760
04:52:54	   14	0.163	   0.754
04:53:48	   15	0.163	   0.754
04:54:43	   16	0.163	   0.750
04:55:35	   17	0.163	   0.760
04:56:28	   18	0.163	   0.750
04:57:21	   19	0.163	   0.758
04:58:13	   20	0.163	   0.758
04:59:10	   21	0.163	   0.746
05:00:03	   22	0.163	   0.756
05:00:55	   23	0.163	   0.768
05:01:47	   24	0.163	   0.746
05:02:40	   25	0.163	   0.756
05:03:36	   26	0.162	   0.766
05:04:30	   27	0.162	   0.750
05:05:23	   28	0.163	   0.778
05:06:16	   29	0.162	   0.762
05:07:08	   30	0.163	   0.750
05:08:04	   31	0.162	   0.748
05:08:57	   32	0.162	   0.770
05:09:51	   33	0.162	   0.756
05:10:43	   34	0.162	   0.750
05:11:37	   35	0.162	   0.758
05:12:33	   36	0.162	   0.754
05:13:26	   37	0.162	   0.754
05:14:18	   38	0.162	   0.766
05:15:12	   39	0.162	   0.752
05:16:05	   40	0.162	   0.744

------------------------------

05:16:08	Parameters at epoch 40:

05:16:08	Theta:
05:16:08		 0.6127   1.9723   0.3175  
05:16:08		-0.6202  -0.4471   0.3529  
05:16:08		 0.0804   0.2136   1.5924  
05:16:08		 0.7256   0.3626   1.2819  
05:16:08	Alpha:
05:16:08		-2.0010  -0.1670  
05:16:08		 0.6383   0.1479  
05:16:08		 0.6320  -1.4768  
05:16:08		-0.1880   0.1304  
05:16:08	Class weight:
05:16:08		 1.0062   1.0434  

------------------------------

05:16:26	Accuracy on test set with the parameters above: 0.767

