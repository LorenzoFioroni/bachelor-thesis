04:39:06	Optimizer: adam
04:39:06	Optimizer params: {'lr': 0.02}
04:39:06	DataSet: non convex - nTrain: 500 - nValid: 0 - nTest: 3000
04:39:06	nLayers: 4 - nEpochs: 40 - batchSize: 32
04:39:06	Cost: weighted fidelity
04:39:06	Seed: None

------------------------------

04:39:10	epoch	loss	accuracy
04:39:15	    0	0.441	   0.332
04:40:10	    1	0.242	   0.618
04:41:01	    2	0.200	   0.682
04:41:57	    3	0.180	   0.746
04:42:50	    4	0.175	   0.740
04:43:42	    5	0.172	   0.738
04:44:38	    6	0.170	   0.728
04:45:30	    7	0.168	   0.750
04:46:23	    8	0.166	   0.746
04:47:15	    9	0.164	   0.762
04:48:08	   10	0.163	   0.762
04:49:05	   11	0.163	   0.788
04:49:57	   12	0.163	   0.762
04:50:49	   13	0.162	   0.784
04:51:42	   14	0.162	   0.786
04:52:35	   15	0.162	   0.786
04:53:32	   16	0.162	   0.788
04:54:25	   17	0.162	   0.772
04:55:17	   18	0.161	   0.790
04:56:10	   19	0.161	   0.786
04:57:03	   20	0.161	   0.790
04:57:59	   21	0.161	   0.784
04:58:51	   22	0.161	   0.780
04:59:44	   23	0.161	   0.794
05:00:38	   24	0.160	   0.784
05:01:31	   25	0.160	   0.792
05:02:27	   26	0.160	   0.782
05:03:20	   27	0.160	   0.786
05:04:13	   28	0.159	   0.792
05:05:05	   29	0.159	   0.786
05:05:59	   30	0.159	   0.792
05:06:55	   31	0.159	   0.786
05:07:48	   32	0.158	   0.784
05:08:42	   33	0.158	   0.788
05:09:36	   34	0.157	   0.796
05:10:29	   35	0.157	   0.798
05:11:25	   36	0.157	   0.790
05:12:18	   37	0.156	   0.798
05:13:11	   38	0.155	   0.798
05:14:05	   39	0.154	   0.800
05:14:58	   40	0.154	   0.788

------------------------------

05:15:02	Parameters at epoch 40:

05:15:02	Theta:
05:15:02		-2.9747  -1.8656  -0.3069  
05:15:02		 0.8843  -1.0782   0.1104  
05:15:02		-1.2812   0.6030   0.2360  
05:15:02		-2.1207   1.7900  -0.8348  
05:15:02	Alpha:
05:15:02		 0.8740   0.3581  
05:15:02		 1.6536  -0.7990  
05:15:02		 0.0206  -0.6296  
05:15:02		-0.7431   0.3612  
05:15:02	Class weight:
05:15:02		 1.0481   1.0456  

------------------------------

05:15:20	Accuracy on test set with the parameters above: 0.782

