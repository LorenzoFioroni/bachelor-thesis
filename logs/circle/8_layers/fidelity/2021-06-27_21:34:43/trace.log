21:34:43	Optimizer: adam
21:34:43	Optimizer params: {'lr': 0.03}
21:34:43	DataSet: circle - nTrain: 500 - nValid: 0 - nTest: 3000
21:34:43	nLayers: 8 - nEpochs: 30 - batchSize: 20
21:34:43	Cost: fidelity
21:34:43	Seed: None

------------------------------

21:34:49	epoch	loss	accuracy
21:34:56	    0	0.443	   0.598
21:36:09	    1	0.289	   0.780
21:37:24	    2	0.268	   0.810
21:38:36	    3	0.272	   0.832
21:39:49	    4	0.267	   0.834
21:41:01	    5	0.269	   0.816
21:42:19	    6	0.271	   0.848
21:43:33	    7	0.263	   0.806
21:44:47	    8	0.262	   0.810
21:46:01	    9	0.263	   0.816
21:47:15	   10	0.268	   0.810
21:48:34	   11	0.262	   0.820
21:49:46	   12	0.247	   0.860
21:51:00	   13	0.235	   0.882
21:52:13	   14	0.231	   0.884
21:53:26	   15	0.227	   0.896
21:54:45	   16	0.232	   0.886
21:55:58	   17	0.237	   0.886
21:57:11	   18	0.234	   0.862
21:58:25	   19	0.228	   0.870
21:59:39	   20	0.228	   0.918
22:00:58	   21	0.220	   0.914
22:02:12	   22	0.218	   0.900
22:03:26	   23	0.218	   0.928
22:04:39	   24	0.214	   0.908
22:05:52	   25	0.212	   0.886
22:07:10	   26	0.215	   0.900
22:08:24	   27	0.207	   0.898
22:09:38	   28	0.204	   0.890
22:10:52	   29	0.202	   0.888
22:12:06	   30	0.200	   0.906

------------------------------

22:12:12	Parameters at epoch 30:

22:12:12	Theta:
22:12:12		-0.0201   0.8448   0.3437  
22:12:12		 0.8299  -0.8621   0.5871  
22:12:12		 0.2464   0.2671   0.3289  
22:12:12		-0.6570  -0.2180  -0.6764  
22:12:12		 0.0746   1.5741  -0.3429  
22:12:12		 1.0240   0.3255  -0.5191  
22:12:12		 0.8515   0.5698   0.4658  
22:12:12		 1.3673  -1.6099  -1.4907  
22:12:12	Alpha:
22:12:12		 1.1366   0.4801  
22:12:12		 1.9832   1.9344  
22:12:12		-0.9710   1.5860  
22:12:12		 0.0523   1.5726  
22:12:12		-0.9538  -1.6941  
22:12:12		-0.6908  -0.8537  
22:12:12		-0.8943  -0.6921  
22:12:12		-0.8695   0.3614  

------------------------------

22:12:38	Accuracy on test set with the parameters above: 0.9033333333333333

