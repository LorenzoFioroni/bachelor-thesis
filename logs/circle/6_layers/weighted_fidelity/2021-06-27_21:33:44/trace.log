21:33:44	Optimizer: adam
21:33:44	Optimizer params: {'lr': 0.03}
21:33:44	DataSet: circle - nTrain: 500 - nValid: 0 - nTest: 3000
21:33:44	nLayers: 6 - nEpochs: 30 - batchSize: 20
21:33:44	Cost: weighted fidelity
21:33:44	Seed: None

------------------------------

21:33:49	epoch	loss	accuracy
21:33:57	    0	0.356	   0.522
21:35:28	    1	0.122	   0.852
21:37:00	    2	0.095	   0.896
21:38:31	    3	0.092	   0.904
21:40:02	    4	0.098	   0.884
21:41:34	    5	0.094	   0.878
21:43:10	    6	0.087	   0.922
21:44:42	    7	0.091	   0.922
21:46:14	    8	0.087	   0.928
21:47:46	    9	0.086	   0.914
21:49:17	   10	0.091	   0.894
21:50:53	   11	0.083	   0.926
21:52:24	   12	0.082	   0.916
21:53:56	   13	0.086	   0.912
21:55:27	   14	0.084	   0.934
21:56:59	   15	0.079	   0.938
21:58:36	   16	0.079	   0.954
22:00:06	   17	0.082	   0.950
22:01:37	   18	0.076	   0.940
22:03:08	   19	0.074	   0.928
22:04:40	   20	0.073	   0.942
22:06:16	   21	0.072	   0.952
22:07:47	   22	0.075	   0.918
22:09:19	   23	0.071	   0.968
22:10:50	   24	0.069	   0.964
22:12:20	   25	0.069	   0.928
22:13:56	   26	0.068	   0.954
22:15:28	   27	0.068	   0.962
22:17:00	   28	0.067	   0.952
22:18:31	   29	0.067	   0.954
22:20:04	   30	0.066	   0.950

------------------------------

22:20:09	Parameters at epoch 30:

22:20:09	Theta:
22:20:09		 0.5625   0.3820  -0.6585  
22:20:09		-1.2204   1.5606   0.5260  
22:20:09		-0.7526   0.2358   1.6135  
22:20:09		 2.1488  -1.1783  -1.3757  
22:20:09		-0.2345  -0.0318   0.3121  
22:20:09		-1.7278   0.8345  -0.3895  
22:20:09	Alpha:
22:20:09		 0.7710   0.8463  
22:20:09		 0.5873   0.8075  
22:20:09		-0.5777  -0.4710  
22:20:09		-1.4777   0.7181  
22:20:09		 2.3620  -1.4313  
22:20:09		 2.0414   0.5644  
22:20:09	Class weight:
22:20:09		 1.0249   1.2151  

------------------------------

22:20:31	Accuracy on test set with the parameters above: 0.9406666666666667

