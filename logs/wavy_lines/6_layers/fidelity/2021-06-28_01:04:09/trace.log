01:04:09	Optimizer: adam
01:04:09	Optimizer params: {'lr': 0.03}
01:04:09	DataSet: wavy lines - nTrain: 500 - nValid: 0 - nTest: 3000
01:04:09	nLayers: 6 - nEpochs: 30 - batchSize: 32
01:04:09	Cost: fidelity
01:04:09	Seed: None

------------------------------

01:04:21	epoch	loss	accuracy
01:04:30	    0	0.449	   0.226
01:05:22	    1	0.202	   0.692
01:06:14	    2	0.170	   0.790
01:07:06	    3	0.163	   0.820
01:07:58	    4	0.151	   0.848
01:08:51	    5	0.143	   0.868
01:09:52	    6	0.132	   0.880
01:10:45	    7	0.126	   0.870
01:11:37	    8	0.124	   0.856
01:12:29	    9	0.120	   0.876
01:13:21	   10	0.114	   0.896
01:14:21	   11	0.113	   0.886
01:15:16	   12	0.107	   0.902
01:16:08	   13	0.102	   0.908
01:17:01	   14	0.098	   0.920
01:17:53	   15	0.097	   0.922
01:18:52	   16	0.095	   0.914
01:19:45	   17	0.093	   0.926
01:20:38	   18	0.092	   0.924
01:21:30	   19	0.091	   0.932
01:22:23	   20	0.091	   0.934
01:23:23	   21	0.089	   0.932
01:24:15	   22	0.089	   0.936
01:25:07	   23	0.088	   0.940
01:25:59	   24	0.088	   0.932
01:26:51	   25	0.087	   0.936
01:27:52	   26	0.087	   0.934
01:28:45	   27	0.087	   0.934
01:29:37	   28	0.086	   0.944
01:30:30	   29	0.086	   0.934
01:31:22	   30	0.086	   0.942

------------------------------

01:31:30	Parameters at epoch 30:

01:31:30	Theta:
01:31:30		-0.7598  -0.4042   1.1216  
01:31:30		 0.0233   0.2894   1.5445  
01:31:30		 0.1187  -0.9568   0.0115  
01:31:30		 0.3113  -0.4650  -0.4169  
01:31:30		-1.3826  -1.1805   1.4293  
01:31:30		-0.6034   0.2803   1.6787  
01:31:30	Alpha:
01:31:30		 0.1713   0.9212  
01:31:30		 2.0732  -0.4937  
01:31:30		 0.4634   1.5928  
01:31:30		 1.1224  -0.7545  
01:31:30		 2.2605   1.5008  
01:31:30		-0.9023  -0.8555  

------------------------------

01:32:17	Accuracy on test set with the parameters above: 0.9266666666666666

