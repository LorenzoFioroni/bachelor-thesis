00:20:07	Optimizer: adam
00:20:07	Optimizer params: {'lr': 0.03}
00:20:07	DataSet: wavy lines - nTrain: 500 - nValid: 0 - nTest: 3000
00:20:07	nLayers: 8 - nEpochs: 30 - batchSize: 32
00:20:07	Cost: weighted fidelity
00:20:07	Seed: None

------------------------------

00:20:16	epoch	loss	accuracy
00:20:32	    0	0.337	   0.194
00:24:47	    1	0.148	   0.668
00:29:04	    2	0.117	   0.660
00:33:21	    3	0.111	   0.694
00:37:38	    4	0.112	   0.730
00:41:54	    5	0.110	   0.742
00:46:21	    6	0.100	   0.746
00:50:39	    7	0.094	   0.764
00:54:57	    8	0.091	   0.784
00:59:14	    9	0.088	   0.788
01:03:31	   10	0.080	   0.836
01:07:56	   11	0.080	   0.774
01:12:13	   12	0.076	   0.824
01:16:31	   13	0.073	   0.840
01:20:49	   14	0.076	   0.840
01:25:05	   15	0.073	   0.850
01:29:32	   16	0.075	   0.778
01:33:50	   17	0.072	   0.860
01:38:08	   18	0.072	   0.848
01:42:26	   19	0.072	   0.836
01:46:44	   20	0.071	   0.830
01:51:11	   21	0.071	   0.818
01:55:30	   22	0.072	   0.814
01:59:48	   23	0.071	   0.814
02:04:07	   24	0.071	   0.846
02:08:26	   25	0.071	   0.818
02:12:53	   26	0.071	   0.864
02:17:13	   27	0.070	   0.840
02:21:31	   28	0.070	   0.828
02:25:50	   29	0.070	   0.834
02:30:09	   30	0.070	   0.804

------------------------------

02:30:18	Parameters at epoch 30:

02:30:18	Theta:
02:30:18		 1.2295   1.1665   2.4595  
02:30:18		-1.7704   0.4201  -2.0016  
02:30:18		-0.8256   1.6732   0.0731  
02:30:18		-2.7131   1.4163   0.3270  
02:30:18		 2.4378  -1.1262  -1.5274  
02:30:18		-0.0647   0.5404   0.1036  
02:30:18		-1.0987  -0.0420   0.0770  
02:30:18		-0.6585   0.3065  -0.7499  
02:30:18	Alpha:
02:30:18		-0.9352   0.4191  
02:30:18		-0.3722  -0.3243  
02:30:18		-1.0736   0.5469  
02:30:18		 2.6869   0.9545  
02:30:18		-1.8723   0.6695  
02:30:18		 0.0129  -0.9151  
02:30:18		 0.6404   1.7833  
02:30:18		 1.9006   0.4818  
02:30:18	Class weight:
02:30:18		 1.6111   0.5080   1.2841   1.2181  

------------------------------

02:31:04	Accuracy on test set with the parameters above: 0.8033333333333333

