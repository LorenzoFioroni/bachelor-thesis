00:22:10	Optimizer: adam
00:22:10	Optimizer params: {'lr': 0.03}
00:22:10	DataSet: wavy lines - nTrain: 500 - nValid: 0 - nTest: 3000
00:22:10	nLayers: 8 - nEpochs: 30 - batchSize: 32
00:22:10	Cost: fidelity
00:22:10	Seed: None

------------------------------

00:22:20	epoch	loss	accuracy
00:22:32	    0	0.685	   0.048
00:23:47	    1	0.262	   0.510
00:25:02	    2	0.169	   0.778
00:26:17	    3	0.138	   0.830
00:27:32	    4	0.133	   0.862
00:28:47	    5	0.126	   0.856
00:30:12	    6	0.121	   0.874
00:31:27	    7	0.124	   0.844
00:32:42	    8	0.119	   0.846
00:33:58	    9	0.118	   0.882
00:35:13	   10	0.118	   0.856
00:36:38	   11	0.123	   0.816
00:37:54	   12	0.116	   0.852
00:39:10	   13	0.113	   0.884
00:40:25	   14	0.115	   0.868
00:41:41	   15	0.113	   0.880
00:43:06	   16	0.110	   0.870
00:44:22	   17	0.109	   0.892
00:45:38	   18	0.107	   0.900
00:46:54	   19	0.110	   0.900
00:48:09	   20	0.105	   0.904
00:49:33	   21	0.106	   0.890
00:50:49	   22	0.103	   0.912
00:52:05	   23	0.105	   0.904
00:53:20	   24	0.104	   0.900
00:54:37	   25	0.102	   0.898
00:56:02	   26	0.102	   0.906
00:57:18	   27	0.101	   0.912
00:58:35	   28	0.100	   0.908
00:59:51	   29	0.100	   0.908
01:01:07	   30	0.100	   0.904

------------------------------

01:01:17	Parameters at epoch 30:

01:01:17	Theta:
01:01:17		 0.0150  -0.1796  -0.1516  
01:01:17		 1.0976   0.6367   0.4307  
01:01:17		 0.2884   2.1177   0.0554  
01:01:17		-0.0184   0.1606   1.2038  
01:01:17		 0.0975  -1.4979   1.3148  
01:01:17		 0.1297  -1.2056   2.4189  
01:01:17		-0.2048   0.4799  -0.9559  
01:01:17		 1.3341   1.6729  -0.5445  
01:01:17	Alpha:
01:01:17		 2.2045   0.5786  
01:01:17		 2.4869   0.7223  
01:01:17		-1.6514   0.7164  
01:01:17		-0.5916   1.0093  
01:01:17		-0.4752  -1.0402  
01:01:17		-0.6073  -0.8300  
01:01:17		 1.0063  -0.9161  
01:01:17		 0.4449   1.5338  

------------------------------

01:02:09	Accuracy on test set with the parameters above: 0.9103333333333333

