02:13:38	Optimizer: adam
02:13:38	Optimizer params: {'lr': 0.02}
02:13:38	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:13:38	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:13:38	Cost: weighted fidelity
02:13:38	Seed: None

------------------------------

02:13:47	epoch	loss	accuracy
02:14:01	    0	0.328	   0.300
02:16:56	    1	0.158	   0.640
02:19:51	    2	0.094	   0.840
02:22:47	    3	0.087	   0.844
02:25:43	    4	0.082	   0.840
02:28:39	    5	0.081	   0.830
02:31:44	    6	0.078	   0.840
02:34:41	    7	0.078	   0.852
02:37:39	    8	0.077	   0.868
02:40:35	    9	0.077	   0.850
02:43:33	   10	0.076	   0.850
02:46:36	   11	0.076	   0.862
02:49:33	   12	0.076	   0.866
02:52:30	   13	0.075	   0.874
02:55:26	   14	0.077	   0.854
02:58:22	   15	0.075	   0.870
03:01:26	   16	0.074	   0.870
03:04:23	   17	0.074	   0.870
03:07:18	   18	0.074	   0.876
03:10:14	   19	0.073	   0.876
03:13:11	   20	0.073	   0.876
03:16:14	   21	0.072	   0.874
03:19:11	   22	0.072	   0.878
03:22:06	   23	0.071	   0.874
03:25:02	   24	0.071	   0.890
03:27:58	   25	0.070	   0.876
03:31:02	   26	0.070	   0.888
03:33:59	   27	0.069	   0.892
03:36:56	   28	0.068	   0.884
03:39:51	   29	0.067	   0.886
03:42:47	   30	0.067	   0.898

------------------------------

03:42:55	Parameters at epoch 30:

03:42:55	Theta:
03:42:55		-2.1629   0.3281   0.3944  
03:42:55		-1.0630   0.2871  -0.6180  
03:42:55		 2.4890  -2.0977   0.4763  
03:42:55		-0.5425   0.0850  -1.3556  
03:42:55		-0.4575  -0.4469   1.0661  
03:42:55		 0.8032   0.1507  -0.5049  
03:42:55	Alpha:
03:42:55		-0.8175   0.4094  
03:42:55		 2.0123  -0.7945  
03:42:55		 0.4337  -0.7519  
03:42:55		-1.5499  -0.0121  
03:42:55		 1.1044   1.8038  
03:42:55		-0.8964  -1.6879  
03:42:55	Class weight:
03:42:55		 1.0917   0.9882   0.7815   1.0098  

------------------------------

03:43:37	Accuracy on test set with the parameters above: 0.8783333333333333

