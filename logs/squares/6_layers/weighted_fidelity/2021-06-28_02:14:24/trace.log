02:14:24	Optimizer: adam
02:14:24	Optimizer params: {'lr': 0.02}
02:14:24	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:14:24	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:14:24	Cost: weighted fidelity
02:14:24	Seed: None

------------------------------

02:14:32	epoch	loss	accuracy
02:14:45	    0	0.349	   0.186
02:17:30	    1	0.154	   0.588
02:20:15	    2	0.095	   0.802
02:23:01	    3	0.083	   0.824
02:25:46	    4	0.079	   0.870
02:28:32	    5	0.078	   0.834
02:31:25	    6	0.075	   0.856
02:34:12	    7	0.073	   0.888
02:36:58	    8	0.071	   0.876
02:39:46	    9	0.070	   0.876
02:42:33	   10	0.070	   0.868
02:45:29	   11	0.069	   0.890
02:48:17	   12	0.068	   0.878
02:51:03	   13	0.068	   0.880
02:53:52	   14	0.067	   0.894
02:56:40	   15	0.068	   0.884
02:59:36	   16	0.067	   0.882
03:02:24	   17	0.067	   0.894
03:05:12	   18	0.066	   0.894
03:08:01	   19	0.066	   0.902
03:10:51	   20	0.066	   0.894
03:13:46	   21	0.066	   0.896
03:16:34	   22	0.066	   0.900
03:19:23	   23	0.066	   0.880
03:22:11	   24	0.066	   0.896
03:25:00	   25	0.066	   0.898
03:27:56	   26	0.066	   0.890
03:30:45	   27	0.066	   0.896
03:33:33	   28	0.066	   0.890
03:36:20	   29	0.066	   0.902
03:39:07	   30	0.065	   0.894

------------------------------

03:39:14	Parameters at epoch 30:

03:39:14	Theta:
03:39:14		 1.9491  -0.4914  -0.6596  
03:39:14		 0.1563   1.8032  -1.4762  
03:39:14		 0.0780  -0.2356  -0.0256  
03:39:14		-0.2768  -2.7185   0.7742  
03:39:14		-0.0052   1.1552  -2.5049  
03:39:14		 0.4131  -1.6803  -1.0505  
03:39:14	Alpha:
03:39:14		 0.4362   0.4152  
03:39:14		 0.2840   0.2323  
03:39:14		 0.2128   2.9484  
03:39:14		 0.7761   1.1606  
03:39:14		-0.8787  -0.9222  
03:39:14		-0.0687   1.7621  
03:39:14	Class weight:
03:39:14		 1.0307   0.8347   0.9868   0.9771  

------------------------------

03:39:54	Accuracy on test set with the parameters above: 0.9093333333333333

