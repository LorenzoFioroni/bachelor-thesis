02:14:04	Optimizer: adam
02:14:04	Optimizer params: {'lr': 0.02}
02:14:04	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:14:04	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:14:04	Cost: weighted fidelity
02:14:04	Seed: None

------------------------------

02:14:12	epoch	loss	accuracy
02:14:27	    0	0.246	   0.398
02:17:29	    1	0.123	   0.696
02:20:35	    2	0.093	   0.770
02:23:39	    3	0.081	   0.828
02:26:45	    4	0.076	   0.850
02:29:50	    5	0.073	   0.860
02:33:02	    6	0.070	   0.876
02:36:07	    7	0.071	   0.878
02:39:12	    8	0.069	   0.892
02:42:17	    9	0.068	   0.876
02:45:22	   10	0.067	   0.882
02:48:36	   11	0.067	   0.900
02:51:42	   12	0.065	   0.898
02:54:48	   13	0.065	   0.894
02:57:55	   14	0.066	   0.890
03:01:00	   15	0.065	   0.886
03:04:15	   16	0.064	   0.888
03:07:21	   17	0.064	   0.904
03:10:28	   18	0.063	   0.896
03:13:35	   19	0.063	   0.900
03:16:43	   20	0.063	   0.908
03:19:58	   21	0.063	   0.894
03:23:06	   22	0.063	   0.902
03:26:11	   23	0.062	   0.904
03:29:17	   24	0.062	   0.904
03:32:22	   25	0.062	   0.910
03:35:36	   26	0.062	   0.910
03:38:42	   27	0.061	   0.910
03:41:48	   28	0.061	   0.912
03:44:54	   29	0.061	   0.914
03:48:00	   30	0.061	   0.912

------------------------------

03:48:09	Parameters at epoch 30:

03:48:09	Theta:
03:48:09		 3.0426   0.6028  -0.9412  
03:48:09		-0.2263   0.4627  -0.9132  
03:48:09		-0.3953  -0.5798  -1.7330  
03:48:09		 0.7296  -1.2270  -0.3010  
03:48:09		 1.1699  -1.2794   1.0700  
03:48:09		-1.2495  -0.5839  -0.1452  
03:48:09	Alpha:
03:48:09		-0.7512   0.1193  
03:48:09		-2.7978  -1.6367  
03:48:09		-0.3079   1.0686  
03:48:09		-0.9915   1.4387  
03:48:09		-1.3023  -0.7832  
03:48:09		-1.1482  -0.6582  
03:48:09	Class weight:
03:48:09		 0.9609   0.8192   1.0691   1.0189  

------------------------------

03:48:55	Accuracy on test set with the parameters above: 0.898

