02:14:15	Optimizer: adam
02:14:15	Optimizer params: {'lr': 0.02}
02:14:15	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:14:15	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:14:15	Cost: weighted fidelity
02:14:15	Seed: None

------------------------------

02:14:24	epoch	loss	accuracy
02:14:37	    0	0.279	   0.292
02:17:34	    1	0.101	   0.820
02:20:33	    2	0.081	   0.864
02:23:32	    3	0.074	   0.914
02:26:29	    4	0.070	   0.920
02:29:28	    5	0.068	   0.918
02:32:34	    6	0.066	   0.920
02:35:34	    7	0.064	   0.914
02:38:34	    8	0.063	   0.920
02:41:35	    9	0.062	   0.932
02:44:34	   10	0.060	   0.936
02:47:40	   11	0.059	   0.940
02:51:16	   12	0.058	   0.940
02:54:16	   13	0.057	   0.930
02:57:18	   14	0.057	   0.940
03:00:19	   15	0.056	   0.936
03:03:30	   16	0.055	   0.930
03:06:31	   17	0.055	   0.944
03:09:32	   18	0.055	   0.934
03:12:36	   19	0.054	   0.932
03:15:40	   20	0.054	   0.936
03:18:52	   21	0.054	   0.932
03:21:55	   22	0.054	   0.940
03:25:00	   23	0.054	   0.938
03:28:06	   24	0.054	   0.928
03:31:11	   25	0.053	   0.932
03:34:24	   26	0.052	   0.934
03:37:27	   27	0.052	   0.942
03:40:31	   28	0.052	   0.936
03:43:37	   29	0.052	   0.934
03:46:41	   30	0.052	   0.938

------------------------------

03:46:50	Parameters at epoch 30:

03:46:50	Theta:
03:46:50		-0.8900   0.3812   0.1643  
03:46:50		 0.1597   0.4962   1.6134  
03:46:50		-1.8451  -1.4492  -0.9814  
03:46:50		-0.6580   1.7382   0.4687  
03:46:50		-0.8855   0.7608   0.1808  
03:46:50		 1.8980   0.5038   2.4597  
03:46:50	Alpha:
03:46:50		 0.2819   0.3735  
03:46:50		 3.1671   0.9948  
03:46:50		 1.9009  -0.1103  
03:46:50		-0.9359   0.8664  
03:46:50		 0.1398  -0.4706  
03:46:50		 0.9925   1.2795  
03:46:50	Class weight:
03:46:50		 1.0077   0.9268   1.0313   0.9062  

------------------------------

03:47:35	Accuracy on test set with the parameters above: 0.901

