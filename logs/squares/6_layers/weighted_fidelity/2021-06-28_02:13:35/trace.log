02:13:35	Optimizer: adam
02:13:35	Optimizer params: {'lr': 0.02}
02:13:35	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:13:35	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:13:35	Cost: weighted fidelity
02:13:35	Seed: None

------------------------------

02:13:45	epoch	loss	accuracy
02:13:59	    0	0.191	   0.500
02:17:02	    1	0.087	   0.800
02:20:07	    2	0.079	   0.848
02:23:12	    3	0.077	   0.842
02:26:17	    4	0.071	   0.872
02:29:21	    5	0.070	   0.862
02:32:36	    6	0.068	   0.886
02:35:40	    7	0.069	   0.866
02:38:45	    8	0.064	   0.896
02:41:51	    9	0.063	   0.892
02:44:58	   10	0.062	   0.906
02:48:12	   11	0.062	   0.894
02:51:18	   12	0.061	   0.904
02:54:25	   13	0.060	   0.910
02:57:31	   14	0.060	   0.908
03:00:38	   15	0.059	   0.914
03:03:54	   16	0.059	   0.910
03:07:00	   17	0.059	   0.910
03:10:08	   18	0.058	   0.914
03:13:14	   19	0.058	   0.920
03:16:22	   20	0.058	   0.914
03:19:36	   21	0.057	   0.922
03:22:43	   22	0.057	   0.924
03:25:48	   23	0.056	   0.920
03:28:55	   24	0.057	   0.918
03:32:01	   25	0.056	   0.924
03:35:17	   26	0.056	   0.926
03:38:23	   27	0.056	   0.924
03:41:30	   28	0.055	   0.926
03:44:36	   29	0.055	   0.922
03:47:43	   30	0.055	   0.924

------------------------------

03:47:52	Parameters at epoch 30:

03:47:52	Theta:
03:47:52		 0.5654  -1.2533  -0.6805  
03:47:52		-0.4125  -1.9099  -1.1448  
03:47:52		 0.3057  -0.7161   2.2616  
03:47:52		 0.5964  -0.4828   0.1819  
03:47:52		 0.9441   1.1567   1.5144  
03:47:52		-0.4692   1.6382   0.7074  
03:47:52	Alpha:
03:47:52		-1.0180   1.3605  
03:47:52		-1.9355   1.0432  
03:47:52		-0.7661  -1.7926  
03:47:52		-1.7351   2.4445  
03:47:52		-0.5870   0.6034  
03:47:52		 1.2002   0.0304  
03:47:52	Class weight:
03:47:52		 0.9956   0.9195   1.0345   0.8878  

------------------------------

03:48:41	Accuracy on test set with the parameters above: 0.91

