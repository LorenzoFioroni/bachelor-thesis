02:58:02	Optimizer: adam
02:58:02	Optimizer params: {'lr': 0.02}
02:58:02	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:58:02	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:58:02	Cost: fidelity
02:58:02	Seed: None

------------------------------

02:58:13	epoch	loss	accuracy
02:58:22	    0	0.653	   0.058
02:59:12	    1	0.269	   0.568
03:00:04	    2	0.190	   0.708
03:00:56	    3	0.151	   0.768
03:01:47	    4	0.143	   0.790
03:02:39	    5	0.139	   0.818
03:03:39	    6	0.139	   0.816
03:04:29	    7	0.134	   0.842
03:05:21	    8	0.132	   0.846
03:06:13	    9	0.130	   0.846
03:07:05	   10	0.129	   0.836
03:08:04	   11	0.128	   0.854
03:08:55	   12	0.127	   0.840
03:09:46	   13	0.125	   0.854
03:10:38	   14	0.124	   0.850
03:11:29	   15	0.123	   0.860
03:12:28	   16	0.123	   0.856
03:13:21	   17	0.122	   0.864
03:14:12	   18	0.122	   0.862
03:15:04	   19	0.121	   0.854
03:15:55	   20	0.121	   0.864
03:16:55	   21	0.120	   0.862
03:17:47	   22	0.120	   0.868
03:18:39	   23	0.119	   0.864
03:19:31	   24	0.118	   0.866
03:20:23	   25	0.118	   0.868
03:21:23	   26	0.118	   0.868
03:22:15	   27	0.117	   0.862
03:23:06	   28	0.117	   0.870
03:23:58	   29	0.117	   0.866
03:24:49	   30	0.116	   0.870

------------------------------

03:24:58	Parameters at epoch 30:

03:24:58	Theta:
03:24:58		-1.7331   0.0933  -0.7333  
03:24:58		-0.7666   0.4571  -0.3707  
03:24:58		 1.4892   1.3528   0.6330  
03:24:58		-1.4904   0.9840   0.1686  
03:24:58		-0.4758  -1.7402   1.9719  
03:24:58		 0.9173  -0.1678  -0.4828  
03:24:58	Alpha:
03:24:58		-0.4553  -0.4273  
03:24:58		-0.9791   0.9540  
03:24:58		-0.3346   0.4790  
03:24:58		-0.3813   0.0253  
03:24:58		-2.1813   0.8215  
03:24:58		-2.0846   0.7539  

------------------------------

03:25:43	Accuracy on test set with the parameters above: 0.866

