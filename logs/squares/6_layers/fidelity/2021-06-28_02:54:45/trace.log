02:54:45	Optimizer: adam
02:54:45	Optimizer params: {'lr': 0.02}
02:54:45	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:54:45	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:54:45	Cost: fidelity
02:54:45	Seed: None

------------------------------

02:54:54	epoch	loss	accuracy
02:55:03	    0	0.499	   0.194
02:55:50	    1	0.307	   0.508
02:56:37	    2	0.221	   0.636
02:57:24	    3	0.185	   0.738
02:58:11	    4	0.179	   0.750
02:58:59	    5	0.174	   0.726
02:59:53	    6	0.160	   0.734
03:00:42	    7	0.142	   0.786
03:01:31	    8	0.134	   0.824
03:02:18	    9	0.129	   0.830
03:03:06	   10	0.126	   0.834
03:04:01	   11	0.126	   0.810
03:04:48	   12	0.122	   0.832
03:05:36	   13	0.121	   0.842
03:06:24	   14	0.122	   0.840
03:07:12	   15	0.119	   0.830
03:08:08	   16	0.117	   0.848
03:08:56	   17	0.116	   0.844
03:09:44	   18	0.115	   0.848
03:10:32	   19	0.115	   0.858
03:11:20	   20	0.113	   0.854
03:12:15	   21	0.112	   0.846
03:13:03	   22	0.111	   0.860
03:13:51	   23	0.110	   0.856
03:14:38	   24	0.109	   0.868
03:15:26	   25	0.109	   0.846
03:16:22	   26	0.107	   0.880
03:17:10	   27	0.106	   0.882
03:17:57	   28	0.105	   0.884
03:18:44	   29	0.104	   0.880
03:19:32	   30	0.103	   0.888

------------------------------

03:19:39	Parameters at epoch 30:

03:19:39	Theta:
03:19:39		 1.2721  -0.5038   0.9013  
03:19:39		-1.3516  -0.4492  -1.8421  
03:19:39		 0.3431  -1.6778   0.2584  
03:19:39		 2.1296  -0.0004   2.1444  
03:19:39		-0.6912  -1.9564  -1.1527  
03:19:39		 0.8567  -0.5079  -0.7861  
03:19:39	Alpha:
03:19:39		 0.6936  -1.3607  
03:19:39		-0.5731  -1.9083  
03:19:39		-1.2795   0.8647  
03:19:39		 0.9237  -0.8590  
03:19:39		 1.2809  -0.7221  
03:19:39		 0.1358  -0.5052  

------------------------------

03:20:18	Accuracy on test set with the parameters above: 0.884

