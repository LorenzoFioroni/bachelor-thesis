02:44:07	Optimizer: adam
02:44:07	Optimizer params: {'lr': 0.02}
02:44:07	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:44:07	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:44:07	Cost: fidelity
02:44:07	Seed: None

------------------------------

02:44:14	epoch	loss	accuracy
02:44:26	    0	0.420	   0.334
02:45:17	    1	0.153	   0.804
02:46:08	    2	0.133	   0.854
02:46:59	    3	0.125	   0.874
02:47:51	    4	0.122	   0.890
02:48:42	    5	0.121	   0.894
02:49:41	    6	0.120	   0.886
02:50:32	    7	0.120	   0.896
02:51:24	    8	0.119	   0.896
02:52:15	    9	0.118	   0.892
02:53:07	   10	0.115	   0.906
02:54:07	   11	0.114	   0.898
02:54:58	   12	0.114	   0.896
02:55:50	   13	0.112	   0.902
02:56:41	   14	0.111	   0.902
02:57:33	   15	0.109	   0.906
02:58:33	   16	0.108	   0.898
02:59:25	   17	0.108	   0.898
03:00:16	   18	0.107	   0.906
03:01:07	   19	0.106	   0.904
03:01:59	   20	0.105	   0.904
03:03:00	   21	0.104	   0.902
03:03:52	   22	0.103	   0.900
03:04:44	   23	0.103	   0.902
03:05:36	   24	0.102	   0.898
03:06:28	   25	0.102	   0.898
03:07:28	   26	0.102	   0.898
03:08:20	   27	0.101	   0.896
03:09:13	   28	0.101	   0.902
03:10:05	   29	0.100	   0.894
03:10:57	   30	0.100	   0.898

------------------------------

03:11:05	Parameters at epoch 30:

03:11:05	Theta:
03:11:05		 0.4464   1.3402  -0.0675  
03:11:05		-1.2318  -1.2833   0.3850  
03:11:05		-0.2363  -1.6581  -0.4672  
03:11:05		-0.2836  -0.3830  -0.5747  
03:11:05		-1.1816  -0.6622  -0.0985  
03:11:05		-0.5627  -1.8872   0.8517  
03:11:05	Alpha:
03:11:05		-1.2973   0.2295  
03:11:05		-0.6180   2.0674  
03:11:05		-1.0844  -0.0365  
03:11:05		 1.3660  -1.0411  
03:11:05		 1.8252   0.9942  
03:11:05		-2.1047  -1.0234  

------------------------------

03:11:48	Accuracy on test set with the parameters above: 0.899

