02:52:38	Optimizer: adam
02:52:38	Optimizer params: {'lr': 0.02}
02:52:38	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:52:38	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:52:38	Cost: fidelity
02:52:38	Seed: None

------------------------------

02:52:48	epoch	loss	accuracy
02:52:56	    0	0.424	   0.426
02:53:43	    1	0.332	   0.530
02:54:29	    2	0.255	   0.558
02:55:16	    3	0.156	   0.798
02:56:03	    4	0.136	   0.852
02:56:49	    5	0.137	   0.842
02:57:43	    6	0.131	   0.844
02:58:30	    7	0.131	   0.848
02:59:17	    8	0.129	   0.846
03:00:04	    9	0.128	   0.856
03:00:51	   10	0.128	   0.854
03:01:45	   11	0.129	   0.856
03:02:31	   12	0.128	   0.856
03:03:18	   13	0.127	   0.862
03:04:05	   14	0.129	   0.860
03:04:52	   15	0.127	   0.858
03:05:46	   16	0.127	   0.858
03:06:33	   17	0.129	   0.862
03:07:19	   18	0.126	   0.858
03:08:06	   19	0.125	   0.858
03:08:53	   20	0.126	   0.862
03:09:47	   21	0.127	   0.862
03:10:34	   22	0.125	   0.872
03:11:21	   23	0.125	   0.868
03:12:08	   24	0.125	   0.870
03:12:55	   25	0.125	   0.866
03:13:49	   26	0.124	   0.868
03:14:36	   27	0.124	   0.866
03:15:23	   28	0.124	   0.870
03:16:10	   29	0.124	   0.872
03:16:57	   30	0.123	   0.874

------------------------------

03:17:04	Parameters at epoch 30:

03:17:04	Theta:
03:17:04		-0.0108  -1.1664   0.6677  
03:17:04		 0.4834   2.3561   0.4575  
03:17:04		-1.0960  -0.1601   0.1548  
03:17:04		-0.1537  -0.1982  -0.7655  
03:17:04		 1.6678  -0.1174  -1.0912  
03:17:04		-1.4054   0.4336  -1.0502  
03:17:04	Alpha:
03:17:04		-0.4230   1.7697  
03:17:04		 1.0710  -0.2420  
03:17:04		-0.5760  -0.0257  
03:17:04		-0.0483   0.6767  
03:17:04		-0.5845  -0.4972  
03:17:04		-0.6996  -0.3663  

------------------------------

03:17:42	Accuracy on test set with the parameters above: 0.8616666666666667

