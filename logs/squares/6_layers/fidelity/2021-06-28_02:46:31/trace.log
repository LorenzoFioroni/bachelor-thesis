02:46:31	Optimizer: adam
02:46:31	Optimizer params: {'lr': 0.02}
02:46:31	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:46:31	nLayers: 6 - nEpochs: 30 - batchSize: 32
02:46:31	Cost: fidelity
02:46:31	Seed: None

------------------------------

02:46:38	epoch	loss	accuracy
02:46:50	    0	0.529	   0.162
02:47:42	    1	0.351	   0.502
02:48:34	    2	0.291	   0.594
02:49:26	    3	0.227	   0.642
02:50:17	    4	0.183	   0.732
02:51:08	    5	0.170	   0.786
02:52:07	    6	0.164	   0.780
02:52:58	    7	0.155	   0.778
02:53:49	    8	0.144	   0.802
02:54:40	    9	0.134	   0.824
02:55:32	   10	0.124	   0.844
02:56:31	   11	0.120	   0.860
02:57:23	   12	0.116	   0.870
02:58:14	   13	0.114	   0.886
02:59:05	   14	0.112	   0.882
02:59:56	   15	0.112	   0.890
03:00:58	   16	0.111	   0.890
03:01:50	   17	0.110	   0.896
03:02:41	   18	0.109	   0.892
03:03:32	   19	0.108	   0.906
03:04:23	   20	0.107	   0.898
03:05:22	   21	0.106	   0.904
03:06:13	   22	0.107	   0.902
03:07:04	   23	0.106	   0.896
03:07:55	   24	0.104	   0.898
03:08:46	   25	0.103	   0.912
03:09:45	   26	0.103	   0.902
03:10:36	   27	0.102	   0.904
03:11:27	   28	0.101	   0.906
03:12:19	   29	0.100	   0.900
03:13:10	   30	0.100	   0.906

------------------------------

03:13:18	Parameters at epoch 30:

03:13:18	Theta:
03:13:18		-1.3106   1.4857  -0.8147  
03:13:18		-0.6499  -0.1382   0.3401  
03:13:18		 1.4665   0.2084   0.2910  
03:13:18		 1.3824   0.8744   0.9245  
03:13:18		-1.2842   0.6372   0.4327  
03:13:18		 1.8515  -0.9779   1.0582  
03:13:18	Alpha:
03:13:18		 1.0755  -0.1471  
03:13:18		-0.7112  -0.3622  
03:13:18		 0.2620  -2.8555  
03:13:18		-1.2112  -1.5368  
03:13:18		-0.5223   0.2748  
03:13:18		-0.8060  -0.4978  

------------------------------

03:14:01	Accuracy on test set with the parameters above: 0.892

