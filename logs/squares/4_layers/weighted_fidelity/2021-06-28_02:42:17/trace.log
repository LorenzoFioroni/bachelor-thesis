02:42:17	Optimizer: adam
02:42:17	Optimizer params: {'lr': 0.02}
02:42:17	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:42:17	nLayers: 4 - nEpochs: 30 - batchSize: 32
02:42:17	Cost: weighted fidelity
02:42:17	Seed: None

------------------------------

02:42:23	epoch	loss	accuracy
02:42:38	    0	0.314	   0.244
02:44:22	    1	0.123	   0.644
02:46:06	    2	0.096	   0.722
02:47:52	    3	0.090	   0.762
02:49:39	    4	0.089	   0.750
02:51:25	    5	0.088	   0.758
02:53:21	    6	0.088	   0.786
02:55:07	    7	0.088	   0.734
02:56:51	    8	0.091	   0.720
02:58:35	    9	0.089	   0.716
03:00:20	   10	0.088	   0.746
03:02:12	   11	0.087	   0.772
03:04:00	   12	0.087	   0.734
03:05:46	   13	0.088	   0.768
03:07:31	   14	0.088	   0.754
03:09:20	   15	0.087	   0.770
03:11:17	   16	0.087	   0.752
03:13:07	   17	0.087	   0.758
03:14:54	   18	0.087	   0.782
03:16:39	   19	0.087	   0.776
03:18:24	   20	0.088	   0.754
03:20:17	   21	0.087	   0.774
03:22:04	   22	0.087	   0.774
03:23:52	   23	0.087	   0.768
03:25:36	   24	0.087	   0.728
03:27:21	   25	0.087	   0.762
03:29:13	   26	0.087	   0.772
03:30:58	   27	0.087	   0.754
03:32:43	   28	0.087	   0.766
03:34:28	   29	0.087	   0.780
03:36:14	   30	0.087	   0.728

------------------------------

03:36:20	Parameters at epoch 30:

03:36:20	Theta:
03:36:20		-0.2015   0.4400  -0.8342  
03:36:20		-1.5556   0.4687   1.2105  
03:36:20		-0.6563   0.0692  -0.2979  
03:36:20		-0.1968  -0.1007   0.5161  
03:36:20	Alpha:
03:36:20		-2.2049  -0.9052  
03:36:20		-0.0633   0.6063  
03:36:20		 0.4817  -0.2427  
03:36:20		 1.2993  -1.1108  
03:36:20	Class weight:
03:36:20		 0.5478   1.2170   1.7568   1.2552  

------------------------------

03:36:56	Accuracy on test set with the parameters above: 0.7256666666666667

