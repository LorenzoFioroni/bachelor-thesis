02:31:57	Optimizer: adam
02:31:57	Optimizer params: {'lr': 0.02}
02:31:57	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:31:57	nLayers: 4 - nEpochs: 30 - batchSize: 32
02:31:57	Cost: weighted fidelity
02:31:57	Seed: None

------------------------------

02:32:03	epoch	loss	accuracy
02:32:15	    0	0.358	   0.178
02:33:51	    1	0.154	   0.570
02:35:27	    2	0.121	   0.752
02:37:02	    3	0.100	   0.776
02:38:38	    4	0.094	   0.792
02:40:14	    5	0.091	   0.826
02:41:55	    6	0.092	   0.798
02:43:31	    7	0.090	   0.806
02:45:07	    8	0.089	   0.818
02:46:44	    9	0.089	   0.830
02:48:20	   10	0.089	   0.806
02:50:01	   11	0.088	   0.834
02:51:37	   12	0.088	   0.812
02:53:13	   13	0.087	   0.838
02:54:49	   14	0.086	   0.818
02:56:26	   15	0.086	   0.824
02:58:08	   16	0.085	   0.838
02:59:45	   17	0.084	   0.850
03:01:21	   18	0.083	   0.848
03:02:58	   19	0.083	   0.850
03:04:35	   20	0.082	   0.850
03:06:17	   21	0.081	   0.858
03:07:52	   22	0.080	   0.860
03:09:29	   23	0.080	   0.858
03:11:04	   24	0.079	   0.864
03:12:40	   25	0.078	   0.864
03:14:21	   26	0.078	   0.860
03:15:58	   27	0.077	   0.872
03:17:35	   28	0.077	   0.874
03:19:12	   29	0.076	   0.878
03:20:48	   30	0.076	   0.866

------------------------------

03:20:54	Parameters at epoch 30:

03:20:54	Theta:
03:20:54		 0.1867  -1.3779   0.5356  
03:20:54		 1.0325  -2.1944   0.6095  
03:20:54		-0.3692  -0.7880   0.7044  
03:20:54		-0.1758   0.9390  -0.1153  
03:20:54	Alpha:
03:20:54		-0.6829   1.4734  
03:20:54		-2.5137   0.1464  
03:20:54		-1.2959  -0.6394  
03:20:54		 0.2780   0.5792  
03:20:54	Class weight:
03:20:54		 1.0517   0.8698   1.0299   0.8636  

------------------------------

03:21:25	Accuracy on test set with the parameters above: 0.8753333333333333

