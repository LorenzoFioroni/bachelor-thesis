02:39:35	Optimizer: adam
02:39:35	Optimizer params: {'lr': 0.02}
02:39:35	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:39:35	nLayers: 4 - nEpochs: 30 - batchSize: 32
02:39:35	Cost: weighted fidelity
02:39:35	Seed: None

------------------------------

02:39:40	epoch	loss	accuracy
02:39:54	    0	0.255	   0.462
02:41:35	    1	0.147	   0.652
02:43:15	    2	0.116	   0.748
02:44:56	    3	0.099	   0.832
02:46:38	    4	0.097	   0.834
02:48:19	    5	0.094	   0.816
02:50:10	    6	0.094	   0.810
02:51:53	    7	0.093	   0.824
02:53:36	    8	0.092	   0.802
02:55:18	    9	0.093	   0.814
02:57:03	   10	0.091	   0.804
02:58:52	   11	0.090	   0.810
03:00:35	   12	0.089	   0.796
03:02:18	   13	0.088	   0.790
03:04:01	   14	0.087	   0.792
03:05:44	   15	0.086	   0.796
03:07:33	   16	0.086	   0.788
03:09:16	   17	0.086	   0.820
03:10:59	   18	0.085	   0.798
03:12:43	   19	0.084	   0.814
03:14:26	   20	0.084	   0.800
03:16:16	   21	0.083	   0.820
03:17:58	   22	0.083	   0.824
03:19:42	   23	0.082	   0.806
03:21:24	   24	0.082	   0.816
03:23:07	   25	0.081	   0.814
03:24:56	   26	0.081	   0.814
03:26:39	   27	0.080	   0.820
03:28:22	   28	0.080	   0.810
03:30:05	   29	0.079	   0.810
03:31:49	   30	0.079	   0.818

------------------------------

03:31:55	Parameters at epoch 30:

03:31:55	Theta:
03:31:55		 2.2532   0.0331  -0.3897  
03:31:55		-0.9907   1.6065   0.8974  
03:31:55		-0.0196   0.2441   0.8696  
03:31:55		-0.0588   0.2392   0.4714  
03:31:55	Alpha:
03:31:55		-1.5473   1.2320  
03:31:55		 1.0242  -0.2053  
03:31:55		-1.0395   1.0846  
03:31:55		-0.4736  -0.8545  
03:31:55	Class weight:
03:31:55		 1.1345   1.0104   0.7672   0.9610  

------------------------------

03:32:30	Accuracy on test set with the parameters above: 0.828

