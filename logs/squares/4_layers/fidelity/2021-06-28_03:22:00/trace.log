03:22:00	Optimizer: adam
03:22:00	Optimizer params: {'lr': 0.02}
03:22:00	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:22:00	nLayers: 4 - nEpochs: 30 - batchSize: 32
03:22:00	Cost: fidelity
03:22:00	Seed: None

------------------------------

03:22:08	epoch	loss	accuracy
03:22:14	    0	0.568	   0.300
03:22:42	    1	0.349	   0.440
03:23:09	    2	0.263	   0.594
03:23:37	    3	0.199	   0.682
03:24:05	    4	0.174	   0.728
03:24:33	    5	0.161	   0.774
03:25:07	    6	0.154	   0.794
03:25:35	    7	0.146	   0.806
03:26:02	    8	0.141	   0.810
03:26:30	    9	0.136	   0.844
03:26:58	   10	0.131	   0.860
03:27:32	   11	0.127	   0.864
03:27:59	   12	0.122	   0.874
03:28:27	   13	0.118	   0.874
03:28:55	   14	0.114	   0.880
03:29:23	   15	0.110	   0.874
03:29:56	   16	0.108	   0.868
03:30:24	   17	0.106	   0.880
03:30:52	   18	0.105	   0.882
03:31:20	   19	0.104	   0.878
03:31:48	   20	0.103	   0.886
03:32:21	   21	0.102	   0.878
03:32:49	   22	0.101	   0.880
03:33:17	   23	0.101	   0.880
03:33:45	   24	0.100	   0.884
03:34:13	   25	0.100	   0.876
03:34:47	   26	0.099	   0.880
03:35:15	   27	0.098	   0.882
03:35:43	   28	0.098	   0.880
03:36:11	   29	0.097	   0.878
03:36:39	   30	0.097	   0.884

------------------------------

03:36:45	Parameters at epoch 30:

03:36:45	Theta:
03:36:45		-0.4065  -1.5465   0.1034  
03:36:45		 1.0112  -1.1730  -1.4436  
03:36:45		-0.4891   0.8393  -2.7199  
03:36:45		-1.9526   1.1647   3.1915  
03:36:45	Alpha:
03:36:45		-0.9234   0.4848  
03:36:45		-1.8777  -2.3347  
03:36:45		 0.9957   1.2507  
03:36:45		 1.2948  -0.9650  

------------------------------

03:37:14	Accuracy on test set with the parameters above: 0.8723333333333333

