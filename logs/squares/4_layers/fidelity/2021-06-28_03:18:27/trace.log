03:18:27	Optimizer: adam
03:18:27	Optimizer params: {'lr': 0.02}
03:18:27	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:18:27	nLayers: 4 - nEpochs: 30 - batchSize: 32
03:18:27	Cost: fidelity
03:18:27	Seed: None

------------------------------

03:18:32	epoch	loss	accuracy
03:18:40	    0	0.542	   0.262
03:19:08	    1	0.266	   0.620
03:19:35	    2	0.185	   0.698
03:20:03	    3	0.155	   0.784
03:20:30	    4	0.147	   0.802
03:20:58	    5	0.142	   0.828
03:21:31	    6	0.140	   0.812
03:21:59	    7	0.138	   0.834
03:22:26	    8	0.137	   0.840
03:22:54	    9	0.137	   0.840
03:23:22	   10	0.136	   0.842
03:23:55	   11	0.136	   0.844
03:24:23	   12	0.135	   0.842
03:24:51	   13	0.134	   0.852
03:25:18	   14	0.134	   0.850
03:25:46	   15	0.133	   0.850
03:26:19	   16	0.133	   0.848
03:26:47	   17	0.133	   0.860
03:27:15	   18	0.132	   0.860
03:27:43	   19	0.131	   0.856
03:28:11	   20	0.131	   0.860
03:28:44	   21	0.131	   0.862
03:29:11	   22	0.130	   0.866
03:29:39	   23	0.130	   0.864
03:30:07	   24	0.129	   0.866
03:30:35	   25	0.129	   0.870
03:31:08	   26	0.128	   0.864
03:31:35	   27	0.128	   0.866
03:32:03	   28	0.128	   0.866
03:32:31	   29	0.128	   0.874
03:32:59	   30	0.127	   0.872

------------------------------

03:33:04	Parameters at epoch 30:

03:33:04	Theta:
03:33:04		-0.4674   1.0800  -0.5529  
03:33:04		-0.8128  -1.2254  -2.5606  
03:33:04		-1.4018   0.7233  -0.1424  
03:33:04		-0.7761   0.1847  -0.1492  
03:33:04	Alpha:
03:33:04		 0.1476  -0.1448  
03:33:04		-1.2717  -0.8255  
03:33:04		 0.7618  -0.2025  
03:33:04		 0.8990   2.0631  

------------------------------

03:33:34	Accuracy on test set with the parameters above: 0.866

