02:59:12	Optimizer: adam
02:59:12	Optimizer params: {'lr': 0.02}
02:59:12	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:59:12	nLayers: 3 - nEpochs: 30 - batchSize: 32
02:59:12	Cost: weighted fidelity
02:59:12	Seed: None

------------------------------

02:59:18	epoch	loss	accuracy
02:59:28	    0	0.342	   0.230
03:00:45	    1	0.158	   0.592
03:02:02	    2	0.122	   0.702
03:03:19	    3	0.104	   0.808
03:04:36	    4	0.095	   0.834
03:05:54	    5	0.090	   0.828
03:07:17	    6	0.087	   0.832
03:08:35	    7	0.084	   0.844
03:09:52	    8	0.083	   0.834
03:11:09	    9	0.082	   0.838
03:12:27	   10	0.081	   0.840
03:13:50	   11	0.080	   0.842
03:15:07	   12	0.080	   0.846
03:16:25	   13	0.079	   0.838
03:17:42	   14	0.079	   0.840
03:19:00	   15	0.078	   0.848
03:20:23	   16	0.078	   0.846
03:21:40	   17	0.078	   0.838
03:22:57	   18	0.077	   0.844
03:24:15	   19	0.077	   0.846
03:25:32	   20	0.077	   0.838
03:26:54	   21	0.077	   0.838
03:28:11	   22	0.076	   0.846
03:29:28	   23	0.076	   0.844
03:30:46	   24	0.076	   0.842
03:32:04	   25	0.076	   0.840
03:33:26	   26	0.076	   0.838
03:34:44	   27	0.075	   0.842
03:36:01	   28	0.075	   0.840
03:37:18	   29	0.075	   0.840
03:38:36	   30	0.075	   0.840

------------------------------

03:38:42	Parameters at epoch 30:

03:38:42	Theta:
03:38:42		-0.4275  -0.5881  -0.6601  
03:38:42		 0.2308  -0.6800   0.4527  
03:38:42		 0.6931  -1.7288   0.1019  
03:38:42	Alpha:
03:38:42		 0.0216  -1.1062  
03:38:42		 0.6091   1.9850  
03:38:42		-2.0069   0.8686  
03:38:42	Class weight:
03:38:42		 1.0130   1.0755   0.9652   0.7739  

------------------------------

03:39:12	Accuracy on test set with the parameters above: 0.8373333333333334

