03:06:33	Optimizer: adam
03:06:33	Optimizer params: {'lr': 0.02}
03:06:33	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:06:33	nLayers: 3 - nEpochs: 30 - batchSize: 32
03:06:33	Cost: weighted fidelity
03:06:33	Seed: None

------------------------------

03:06:40	epoch	loss	accuracy
03:06:49	    0	0.307	   0.294
03:07:57	    1	0.119	   0.752
03:09:04	    2	0.096	   0.780
03:10:12	    3	0.088	   0.798
03:11:19	    4	0.085	   0.796
03:12:26	    5	0.083	   0.800
03:13:39	    6	0.082	   0.816
03:14:47	    7	0.082	   0.796
03:15:55	    8	0.081	   0.804
03:17:03	    9	0.081	   0.812
03:18:11	   10	0.080	   0.810
03:19:23	   11	0.081	   0.820
03:20:31	   12	0.081	   0.782
03:21:39	   13	0.080	   0.806
03:22:46	   14	0.080	   0.800
03:23:54	   15	0.080	   0.800
03:25:07	   16	0.080	   0.806
03:26:15	   17	0.080	   0.794
03:27:22	   18	0.080	   0.798
03:28:30	   19	0.080	   0.802
03:29:38	   20	0.080	   0.796
03:30:51	   21	0.080	   0.806
03:31:58	   22	0.081	   0.810
03:33:07	   23	0.080	   0.800
03:34:15	   24	0.080	   0.804
03:35:22	   25	0.079	   0.800
03:36:36	   26	0.079	   0.806
03:37:44	   27	0.079	   0.802
03:38:52	   28	0.079	   0.800
03:40:01	   29	0.079	   0.798
03:41:08	   30	0.079	   0.812

------------------------------

03:41:14	Parameters at epoch 30:

03:41:14	Theta:
03:41:14		 0.9649  -2.1347  -1.3008  
03:41:14		 0.9531   0.1427  -0.4386  
03:41:14		-0.9448   0.2578   0.5732  
03:41:14	Alpha:
03:41:14		 0.6253  -1.1219  
03:41:14		-1.7318  -0.7204  
03:41:14		 0.6968   0.3588  
03:41:14	Class weight:
03:41:14		 1.7622   1.1131   0.6048   1.1380  

------------------------------

03:41:41	Accuracy on test set with the parameters above: 0.8143333333333334

