03:10:53	Optimizer: adam
03:10:53	Optimizer params: {'lr': 0.02}
03:10:53	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:10:53	nLayers: 3 - nEpochs: 30 - batchSize: 32
03:10:53	Cost: weighted fidelity
03:10:53	Seed: None

------------------------------

03:10:59	epoch	loss	accuracy
03:11:10	    0	0.255	   0.446
03:12:21	    1	0.148	   0.604
03:13:33	    2	0.127	   0.666
03:14:44	    3	0.113	   0.726
03:15:56	    4	0.105	   0.752
03:17:08	    5	0.101	   0.790
03:18:25	    6	0.096	   0.792
03:19:37	    7	0.090	   0.822
03:20:49	    8	0.087	   0.830
03:22:01	    9	0.086	   0.834
03:23:12	   10	0.084	   0.824
03:24:29	   11	0.083	   0.828
03:25:42	   12	0.082	   0.840
03:26:54	   13	0.083	   0.814
03:28:06	   14	0.082	   0.830
03:29:18	   15	0.081	   0.826
03:30:36	   16	0.081	   0.832
03:31:47	   17	0.081	   0.818
03:33:00	   18	0.081	   0.828
03:34:12	   19	0.081	   0.818
03:35:24	   20	0.080	   0.832
03:36:41	   21	0.080	   0.834
03:37:53	   22	0.080	   0.836
03:39:05	   23	0.080	   0.816
03:40:17	   24	0.080	   0.838
03:41:29	   25	0.079	   0.822
03:42:46	   26	0.079	   0.836
03:43:58	   27	0.079	   0.826
03:45:10	   28	0.079	   0.834
03:46:23	   29	0.079	   0.830
03:47:34	   30	0.079	   0.830

------------------------------

03:47:40	Parameters at epoch 30:

03:47:40	Theta:
03:47:40		 0.9252  -0.8113   1.0008  
03:47:40		 0.8973   0.2847  -0.0868  
03:47:40		-2.0034   0.9210  -0.2556  
03:47:40	Alpha:
03:47:40		 0.7151  -1.1029  
03:47:40		-2.0310  -0.4303  
03:47:40		 0.7027   0.0351  
03:47:40	Class weight:
03:47:40		 0.6282   1.1003   1.5087   1.1291  

------------------------------

03:48:08	Accuracy on test set with the parameters above: 0.8196666666666667

