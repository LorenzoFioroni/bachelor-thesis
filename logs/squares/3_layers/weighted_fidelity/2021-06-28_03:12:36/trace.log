03:12:36	Optimizer: adam
03:12:36	Optimizer params: {'lr': 0.02}
03:12:36	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:12:36	nLayers: 3 - nEpochs: 30 - batchSize: 32
03:12:36	Cost: weighted fidelity
03:12:36	Seed: None

------------------------------

03:12:44	epoch	loss	accuracy
03:12:54	    0	0.241	   0.474
03:14:07	    1	0.115	   0.698
03:15:21	    2	0.096	   0.758
03:16:35	    3	0.088	   0.802
03:17:49	    4	0.085	   0.824
03:19:02	    5	0.083	   0.842
03:20:22	    6	0.084	   0.850
03:21:36	    7	0.082	   0.840
03:22:49	    8	0.081	   0.862
03:24:04	    9	0.081	   0.840
03:25:18	   10	0.081	   0.876
03:26:38	   11	0.081	   0.878
03:27:52	   12	0.080	   0.876
03:29:07	   13	0.080	   0.872
03:30:22	   14	0.080	   0.874
03:31:37	   15	0.080	   0.874
03:32:58	   16	0.080	   0.878
03:34:14	   17	0.080	   0.874
03:35:29	   18	0.080	   0.880
03:36:44	   19	0.079	   0.880
03:37:59	   20	0.079	   0.890
03:39:18	   21	0.079	   0.880
03:40:32	   22	0.079	   0.882
03:41:47	   23	0.079	   0.880
03:43:01	   24	0.079	   0.884
03:44:15	   25	0.079	   0.890
03:45:35	   26	0.079	   0.878
03:46:50	   27	0.078	   0.884
03:48:05	   28	0.078	   0.886
03:49:21	   29	0.078	   0.894
03:50:36	   30	0.078	   0.892

------------------------------

03:50:42	Parameters at epoch 30:

03:50:42	Theta:
03:50:42		-1.7907   1.1917   0.1304  
03:50:42		 1.1437   2.3795  -0.9680  
03:50:42		 0.2926  -0.5348   1.3030  
03:50:42	Alpha:
03:50:42		 0.3921   1.1570  
03:50:42		-1.2946   1.0603  
03:50:42		-1.7885  -0.6461  
03:50:42	Class weight:
03:50:42		 1.2214   1.1616   0.6257   1.1564  

------------------------------

03:51:11	Accuracy on test set with the parameters above: 0.9006666666666666

