03:40:37	Optimizer: adam
03:40:37	Optimizer params: {'lr': 0.02}
03:40:37	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:40:37	nLayers: 3 - nEpochs: 30 - batchSize: 32
03:40:37	Cost: fidelity
03:40:37	Seed: None

------------------------------

03:40:44	epoch	loss	accuracy
03:40:49	    0	0.587	   0.148
03:41:09	    1	0.320	   0.502
03:41:29	    2	0.181	   0.796
03:41:49	    3	0.144	   0.838
03:42:09	    4	0.139	   0.848
03:42:29	    5	0.136	   0.846
03:42:54	    6	0.133	   0.840
03:43:13	    7	0.133	   0.842
03:43:33	    8	0.132	   0.844
03:43:53	    9	0.132	   0.854
03:44:13	   10	0.132	   0.842
03:44:38	   11	0.131	   0.844
03:44:58	   12	0.131	   0.846
03:45:17	   13	0.131	   0.836
03:45:37	   14	0.131	   0.852
03:45:57	   15	0.130	   0.842
03:46:21	   16	0.130	   0.838
03:46:41	   17	0.130	   0.844
03:47:01	   18	0.130	   0.844
03:47:21	   19	0.130	   0.838
03:47:41	   20	0.130	   0.848
03:48:06	   21	0.129	   0.852
03:48:26	   22	0.129	   0.834
03:48:46	   23	0.129	   0.842
03:49:06	   24	0.129	   0.850
03:49:26	   25	0.129	   0.842
03:49:51	   26	0.128	   0.852
03:50:10	   27	0.128	   0.848
03:50:30	   28	0.128	   0.838
03:50:50	   29	0.128	   0.846
03:51:10	   30	0.128	   0.836

------------------------------

03:51:15	Parameters at epoch 30:

03:51:15	Theta:
03:51:15		 0.7059   1.8500  -0.9630  
03:51:15		 0.5655  -0.8551   1.2140  
03:51:15		 0.6830   0.1926   0.7630  
03:51:15	Alpha:
03:51:15		 1.1419   1.6426  
03:51:15		-1.6156   0.1989  
03:51:15		-0.7115   0.4500  

------------------------------

03:51:41	Accuracy on test set with the parameters above: 0.828

