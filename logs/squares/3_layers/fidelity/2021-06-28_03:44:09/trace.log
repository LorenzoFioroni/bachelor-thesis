03:44:09	Optimizer: adam
03:44:09	Optimizer params: {'lr': 0.02}
03:44:09	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:44:09	nLayers: 3 - nEpochs: 30 - batchSize: 32
03:44:09	Cost: fidelity
03:44:09	Seed: None

------------------------------

03:44:14	epoch	loss	accuracy
03:44:22	    0	0.491	   0.250
03:44:44	    1	0.277	   0.572
03:45:07	    2	0.218	   0.662
03:45:29	    3	0.196	   0.686
03:45:51	    4	0.181	   0.714
03:46:14	    5	0.171	   0.724
03:46:42	    6	0.162	   0.740
03:47:04	    7	0.156	   0.758
03:47:26	    8	0.152	   0.774
03:47:49	    9	0.150	   0.780
03:48:11	   10	0.148	   0.792
03:48:39	   11	0.147	   0.804
03:49:01	   12	0.146	   0.808
03:49:24	   13	0.145	   0.812
03:49:46	   14	0.144	   0.816
03:50:08	   15	0.143	   0.820
03:50:36	   16	0.142	   0.820
03:50:58	   17	0.142	   0.834
03:51:21	   18	0.141	   0.840
03:51:43	   19	0.140	   0.844
03:52:06	   20	0.139	   0.840
03:52:34	   21	0.138	   0.840
03:52:56	   22	0.137	   0.838
03:53:18	   23	0.136	   0.840
03:53:40	   24	0.135	   0.834
03:54:03	   25	0.135	   0.846
03:54:31	   26	0.134	   0.838
03:54:53	   27	0.134	   0.834
03:55:15	   28	0.133	   0.840
03:55:38	   29	0.133	   0.840
03:56:00	   30	0.133	   0.840

------------------------------

03:56:06	Parameters at epoch 30:

03:56:06	Theta:
03:56:06		-2.1429   2.3792   0.8443  
03:56:06		-0.6223  -1.3766  -0.3858  
03:56:06		 1.3969   0.4200   1.2425  
03:56:06	Alpha:
03:56:06		 2.2918  -1.2039  
03:56:06		-1.1803   0.0186  
03:56:06		-1.2593   0.7570  

------------------------------

03:56:35	Accuracy on test set with the parameters above: 0.837

