03:37:08	Optimizer: adam
03:37:08	Optimizer params: {'lr': 0.02}
03:37:08	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:37:08	nLayers: 2 - nEpochs: 30 - batchSize: 32
03:37:08	Cost: weighted fidelity
03:37:08	Seed: None

------------------------------

03:37:12	epoch	loss	accuracy
03:37:21	    0	0.358	   0.258
03:38:04	    1	0.152	   0.386
03:38:47	    2	0.116	   0.648
03:39:31	    3	0.108	   0.696
03:40:14	    4	0.099	   0.724
03:40:58	    5	0.094	   0.732
03:41:46	    6	0.091	   0.796
03:42:30	    7	0.089	   0.800
03:43:13	    8	0.088	   0.808
03:43:56	    9	0.088	   0.806
03:44:40	   10	0.087	   0.810
03:45:28	   11	0.087	   0.804
03:46:11	   12	0.087	   0.812
03:46:55	   13	0.086	   0.814
03:47:39	   14	0.086	   0.804
03:48:23	   15	0.086	   0.810
03:49:10	   16	0.086	   0.808
03:49:54	   17	0.085	   0.814
03:50:38	   18	0.085	   0.806
03:51:22	   19	0.085	   0.812
03:52:06	   20	0.085	   0.804
03:52:54	   21	0.085	   0.816
03:53:38	   22	0.085	   0.810
03:54:21	   23	0.085	   0.802
03:55:05	   24	0.085	   0.806
03:55:48	   25	0.085	   0.814
03:56:36	   26	0.085	   0.810
03:57:20	   27	0.085	   0.808
03:58:04	   28	0.084	   0.806
03:58:47	   29	0.084	   0.798
03:59:31	   30	0.084	   0.808

------------------------------

03:59:36	Parameters at epoch 30:

03:59:36	Theta:
03:59:36		 1.1756  -0.5678   0.1156  
03:59:36		-0.0185   0.5473  -0.7786  
03:59:36	Alpha:
03:59:36		 2.2684  -0.8685  
03:59:36		-1.4565  -0.3316  
03:59:36	Class weight:
03:59:36		 0.5806   1.1893   1.5749   1.2149  

------------------------------

03:59:58	Accuracy on test set with the parameters above: 0.8163333333333334

