03:37:37	Optimizer: adam
03:37:37	Optimizer params: {'lr': 0.02}
03:37:37	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:37:37	nLayers: 2 - nEpochs: 30 - batchSize: 32
03:37:37	Cost: weighted fidelity
03:37:37	Seed: None

------------------------------

03:37:42	epoch	loss	accuracy
03:37:51	    0	0.312	   0.224
03:38:38	    1	0.138	   0.570
03:39:25	    2	0.090	   0.770
03:40:11	    3	0.086	   0.782
03:40:58	    4	0.083	   0.814
03:41:45	    5	0.081	   0.804
03:42:37	    6	0.080	   0.816
03:43:24	    7	0.080	   0.818
03:44:11	    8	0.082	   0.782
03:44:58	    9	0.080	   0.822
03:45:46	   10	0.079	   0.828
03:46:39	   11	0.079	   0.796
03:47:27	   12	0.079	   0.834
03:48:14	   13	0.078	   0.826
03:49:01	   14	0.079	   0.822
03:49:48	   15	0.078	   0.834
03:50:40	   16	0.078	   0.830
03:51:27	   17	0.078	   0.822
03:52:15	   18	0.078	   0.830
03:53:02	   19	0.078	   0.832
03:53:49	   20	0.078	   0.824
03:54:41	   21	0.078	   0.844
03:55:29	   22	0.078	   0.842
03:56:16	   23	0.078	   0.834
03:57:03	   24	0.078	   0.830
03:57:51	   25	0.078	   0.826
03:58:43	   26	0.078	   0.840
03:59:30	   27	0.078	   0.830
04:00:18	   28	0.078	   0.834
04:01:06	   29	0.078	   0.842
04:01:54	   30	0.077	   0.834

------------------------------

04:01:59	Parameters at epoch 30:

04:01:59	Theta:
04:01:59		-1.8548   0.6892   0.6142  
04:01:59		-0.0468  -2.6169  -0.6718  
04:01:59	Alpha:
04:01:59		 0.2518   0.9850  
04:01:59		 1.2716  -0.4265  
04:01:59	Class weight:
04:01:59		 1.7435   1.2083   0.5531   1.1552  

------------------------------

04:02:24	Accuracy on test set with the parameters above: 0.799

