03:32:01	Optimizer: adam
03:32:01	Optimizer params: {'lr': 0.02}
03:32:01	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:32:01	nLayers: 2 - nEpochs: 30 - batchSize: 32
03:32:01	Cost: weighted fidelity
03:32:01	Seed: None

------------------------------

03:32:08	epoch	loss	accuracy
03:32:16	    0	0.348	   0.110
03:33:02	    1	0.208	   0.506
03:33:49	    2	0.168	   0.496
03:34:35	    3	0.149	   0.534
03:35:22	    4	0.141	   0.560
03:36:09	    5	0.135	   0.580
03:37:00	    6	0.132	   0.592
03:37:48	    7	0.128	   0.608
03:38:35	    8	0.125	   0.628
03:39:22	    9	0.123	   0.660
03:40:10	   10	0.121	   0.628
03:41:01	   11	0.117	   0.646
03:41:48	   12	0.115	   0.646
03:42:35	   13	0.113	   0.648
03:43:23	   14	0.111	   0.638
03:44:10	   15	0.109	   0.682
03:45:02	   16	0.107	   0.640
03:45:49	   17	0.106	   0.668
03:46:36	   18	0.105	   0.684
03:47:23	   19	0.105	   0.674
03:48:10	   20	0.104	   0.700
03:49:01	   21	0.103	   0.720
03:49:47	   22	0.103	   0.684
03:50:33	   23	0.102	   0.750
03:51:20	   24	0.101	   0.720
03:52:06	   25	0.100	   0.746
03:52:56	   26	0.100	   0.754
03:53:43	   27	0.099	   0.742
03:54:29	   28	0.098	   0.764
03:55:15	   29	0.098	   0.756
03:56:02	   30	0.097	   0.752

------------------------------

03:56:06	Parameters at epoch 30:

03:56:06	Theta:
03:56:06		-0.6303  -2.4360  -1.5253  
03:56:06		-0.9505  -0.4823  -0.0929  
03:56:06	Alpha:
03:56:06		-1.1774  -1.1499  
03:56:06		 0.6840   1.9903  
03:56:06	Class weight:
03:56:06		 1.7061   0.6064   0.8404   1.7739  

------------------------------

03:56:29	Accuracy on test set with the parameters above: 0.7356666666666667

