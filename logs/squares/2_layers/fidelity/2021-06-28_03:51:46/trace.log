03:51:46	Optimizer: adam
03:51:46	Optimizer params: {'lr': 0.02}
03:51:46	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:51:46	nLayers: 2 - nEpochs: 30 - batchSize: 32
03:51:46	Cost: fidelity
03:51:46	Seed: None

------------------------------

03:51:50	epoch	loss	accuracy
03:51:57	    0	0.603	   0.244
03:52:12	    1	0.462	   0.244
03:52:27	    2	0.355	   0.398
03:52:42	    3	0.305	   0.486
03:52:58	    4	0.280	   0.580
03:53:13	    5	0.257	   0.594
03:53:33	    6	0.234	   0.622
03:53:48	    7	0.214	   0.662
03:54:03	    8	0.197	   0.706
03:54:18	    9	0.183	   0.730
03:54:34	   10	0.172	   0.746
03:54:54	   11	0.163	   0.750
03:55:09	   12	0.158	   0.758
03:55:24	   13	0.156	   0.770
03:55:39	   14	0.154	   0.782
03:55:54	   15	0.153	   0.778
03:56:13	   16	0.152	   0.790
03:56:28	   17	0.151	   0.786
03:56:44	   18	0.150	   0.794
03:56:59	   19	0.149	   0.786
03:57:14	   20	0.148	   0.798
03:57:34	   21	0.148	   0.784
03:57:49	   22	0.147	   0.800
03:58:05	   23	0.146	   0.800
03:58:19	   24	0.146	   0.796
03:58:34	   25	0.145	   0.808
03:58:54	   26	0.145	   0.808
03:59:09	   27	0.144	   0.804
03:59:24	   28	0.144	   0.810
03:59:38	   29	0.144	   0.814
03:59:53	   30	0.143	   0.812

------------------------------

03:59:58	Parameters at epoch 30:

03:59:58	Theta:
03:59:58		 0.8897   1.4479  -0.3523  
03:59:58		-0.0472  -0.6848   2.6538  
03:59:58	Alpha:
03:59:58		-0.4536   1.5597  
03:59:58		-1.9756   0.6327  

------------------------------

04:00:22	Accuracy on test set with the parameters above: 0.8293333333333334

