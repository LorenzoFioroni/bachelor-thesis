03:52:12	Optimizer: adam
03:52:12	Optimizer params: {'lr': 0.02}
03:52:12	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:52:12	nLayers: 2 - nEpochs: 30 - batchSize: 32
03:52:12	Cost: fidelity
03:52:12	Seed: None

------------------------------

03:52:17	epoch	loss	accuracy
03:52:22	    0	0.509	   0.254
03:52:35	    1	0.385	   0.254
03:52:48	    2	0.262	   0.546
03:53:02	    3	0.202	   0.718
03:53:15	    4	0.184	   0.746
03:53:29	    5	0.182	   0.738
03:53:46	    6	0.181	   0.746
03:53:59	    7	0.181	   0.748
03:54:13	    8	0.181	   0.750
03:54:26	    9	0.181	   0.754
03:54:40	   10	0.180	   0.754
03:54:57	   11	0.180	   0.752
03:55:11	   12	0.179	   0.752
03:55:24	   13	0.179	   0.746
03:55:37	   14	0.179	   0.754
03:55:51	   15	0.178	   0.756
03:56:08	   16	0.178	   0.754
03:56:22	   17	0.177	   0.754
03:56:35	   18	0.177	   0.752
03:56:49	   19	0.176	   0.754
03:57:02	   20	0.176	   0.760
03:57:20	   21	0.175	   0.754
03:57:33	   22	0.175	   0.754
03:57:47	   23	0.174	   0.750
03:58:00	   24	0.174	   0.762
03:58:13	   25	0.173	   0.760
03:58:30	   26	0.172	   0.760
03:58:44	   27	0.172	   0.758
03:58:57	   28	0.171	   0.764
03:59:10	   29	0.171	   0.770
03:59:24	   30	0.170	   0.766

------------------------------

03:59:28	Parameters at epoch 30:

03:59:28	Theta:
03:59:28		 0.0838   1.0936  -0.3353  
03:59:28		-1.4177  -2.4631   1.0666  
03:59:28	Alpha:
03:59:28		-0.6206  -0.1431  
03:59:28		-1.7087  -2.1786  

------------------------------

03:59:49	Accuracy on test set with the parameters above: 0.769

