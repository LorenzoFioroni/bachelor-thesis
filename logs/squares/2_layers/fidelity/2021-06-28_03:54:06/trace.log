03:54:06	Optimizer: adam
03:54:06	Optimizer params: {'lr': 0.02}
03:54:06	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:54:06	nLayers: 2 - nEpochs: 30 - batchSize: 32
03:54:06	Cost: fidelity
03:54:06	Seed: None

------------------------------

03:54:10	epoch	loss	accuracy
03:54:16	    0	0.461	   0.232
03:54:30	    1	0.332	   0.342
03:54:43	    2	0.295	   0.456
03:54:57	    3	0.265	   0.616
03:55:11	    4	0.232	   0.684
03:55:25	    5	0.198	   0.736
03:55:42	    6	0.182	   0.750
03:55:56	    7	0.174	   0.766
03:56:10	    8	0.169	   0.782
03:56:24	    9	0.164	   0.784
03:56:37	   10	0.161	   0.782
03:56:55	   11	0.159	   0.786
03:57:09	   12	0.157	   0.786
03:57:23	   13	0.156	   0.788
03:57:37	   14	0.155	   0.790
03:57:51	   15	0.154	   0.794
03:58:08	   16	0.154	   0.790
03:58:22	   17	0.153	   0.786
03:58:36	   18	0.153	   0.792
03:58:50	   19	0.152	   0.794
03:59:03	   20	0.152	   0.792
03:59:22	   21	0.151	   0.800
03:59:35	   22	0.151	   0.794
03:59:49	   23	0.150	   0.802
04:00:03	   24	0.149	   0.798
04:00:17	   25	0.149	   0.796
04:00:35	   26	0.148	   0.794
04:00:49	   27	0.148	   0.800
04:01:02	   28	0.147	   0.802
04:01:16	   29	0.147	   0.806
04:01:30	   30	0.146	   0.812

------------------------------

04:01:34	Parameters at epoch 30:

04:01:34	Theta:
04:01:34		-2.0770   1.3129  -0.2989  
04:01:34		-2.7922   0.4865  -0.8958  
04:01:34	Alpha:
04:01:34		-0.7452  -1.5967  
04:01:34		-1.7529   0.9317  

------------------------------

04:01:56	Accuracy on test set with the parameters above: 0.798

