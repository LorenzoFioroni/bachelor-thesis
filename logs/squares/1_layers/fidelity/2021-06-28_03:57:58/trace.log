03:57:58	Optimizer: adam
03:57:58	Optimizer params: {'lr': 0.02}
03:57:58	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:57:58	nLayers: 1 - nEpochs: 30 - batchSize: 32
03:57:58	Cost: fidelity
03:57:58	Seed: None

------------------------------

03:58:01	epoch	loss	accuracy
03:58:06	    0	0.477	   0.382
03:58:14	    1	0.401	   0.394
03:58:23	    2	0.336	   0.400
03:58:31	    3	0.309	   0.402
03:58:39	    4	0.295	   0.414
03:58:48	    5	0.289	   0.446
03:59:00	    6	0.286	   0.470
03:59:08	    7	0.286	   0.472
03:59:17	    8	0.285	   0.484
03:59:26	    9	0.285	   0.484
03:59:34	   10	0.285	   0.480
03:59:46	   11	0.285	   0.472
03:59:55	   12	0.285	   0.482
04:00:03	   13	0.285	   0.480
04:00:11	   14	0.285	   0.482
04:00:20	   15	0.285	   0.484
04:00:32	   16	0.285	   0.474
04:00:40	   17	0.285	   0.482
04:00:49	   18	0.285	   0.490
04:00:57	   19	0.285	   0.480
04:01:06	   20	0.285	   0.480
04:01:18	   21	0.285	   0.488
04:01:26	   22	0.285	   0.484
04:01:35	   23	0.285	   0.480
04:01:43	   24	0.285	   0.488
04:01:51	   25	0.285	   0.490
04:02:03	   26	0.285	   0.488
04:02:12	   27	0.285	   0.484
04:02:20	   28	0.285	   0.480
04:02:29	   29	0.285	   0.488
04:02:37	   30	0.285	   0.490

------------------------------

04:02:41	Parameters at epoch 30:

04:02:41	Theta:
04:02:41		 0.4988  -0.6139  -0.5960  
04:02:41	Alpha:
04:02:41		-0.2771  -2.3413  

------------------------------

04:02:59	Accuracy on test set with the parameters above: 0.46166666666666667

