03:57:56	Optimizer: adam
03:57:56	Optimizer params: {'lr': 0.02}
03:57:56	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:57:56	nLayers: 1 - nEpochs: 30 - batchSize: 32
03:57:56	Cost: fidelity
03:57:56	Seed: None

------------------------------

03:58:01	epoch	loss	accuracy
03:58:05	    0	0.557	   0.234
03:58:14	    1	0.498	   0.250
03:58:22	    2	0.446	   0.250
03:58:31	    3	0.376	   0.282
03:58:40	    4	0.326	   0.412
03:58:48	    5	0.306	   0.462
03:59:01	    6	0.297	   0.464
03:59:09	    7	0.294	   0.440
03:59:18	    8	0.294	   0.434
03:59:27	    9	0.293	   0.428
03:59:35	   10	0.293	   0.428
03:59:48	   11	0.293	   0.422
03:59:57	   12	0.293	   0.430
04:00:05	   13	0.293	   0.438
04:00:14	   14	0.293	   0.410
04:00:22	   15	0.293	   0.436
04:00:35	   16	0.293	   0.440
04:00:43	   17	0.292	   0.438
04:00:52	   18	0.292	   0.434
04:01:00	   19	0.292	   0.438
04:01:09	   20	0.292	   0.436
04:01:21	   21	0.292	   0.438
04:01:30	   22	0.292	   0.434
04:01:39	   23	0.292	   0.436
04:01:47	   24	0.292	   0.438
04:01:56	   25	0.292	   0.442
04:02:08	   26	0.292	   0.452
04:02:17	   27	0.292	   0.452
04:02:26	   28	0.292	   0.452
04:02:34	   29	0.292	   0.442
04:02:43	   30	0.291	   0.466

------------------------------

04:02:47	Parameters at epoch 30:

04:02:47	Theta:
04:02:47		-0.1388  -0.6877   0.1380  
04:02:47	Alpha:
04:02:47		-1.3676  -2.2658  

------------------------------

04:03:06	Accuracy on test set with the parameters above: 0.41233333333333333

