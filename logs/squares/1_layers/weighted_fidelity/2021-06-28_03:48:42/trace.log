03:48:42	Optimizer: adam
03:48:42	Optimizer params: {'lr': 0.02}
03:48:42	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:48:42	nLayers: 1 - nEpochs: 30 - batchSize: 32
03:48:42	Cost: weighted fidelity
03:48:42	Seed: None

------------------------------

03:48:47	epoch	loss	accuracy
03:48:54	    0	0.425	   0.084
03:49:18	    1	0.282	   0.160
03:49:43	    2	0.220	   0.318
03:50:08	    3	0.183	   0.364
03:50:33	    4	0.167	   0.220
03:50:58	    5	0.165	   0.248
03:51:27	    6	0.163	   0.496
03:51:51	    7	0.161	   0.426
03:52:16	    8	0.158	   0.488
03:52:41	    9	0.155	   0.498
03:53:06	   10	0.151	   0.480
03:53:35	   11	0.149	   0.492
03:54:00	   12	0.146	   0.456
03:54:25	   13	0.144	   0.496
03:54:50	   14	0.142	   0.484
03:55:15	   15	0.140	   0.460
03:55:43	   16	0.139	   0.498
03:56:08	   17	0.138	   0.490
03:56:33	   18	0.138	   0.494
03:56:59	   19	0.138	   0.490
03:57:24	   20	0.137	   0.482
03:57:52	   21	0.137	   0.490
03:58:17	   22	0.137	   0.488
03:58:42	   23	0.137	   0.488
03:59:07	   24	0.136	   0.484
03:59:32	   25	0.136	   0.472
04:00:01	   26	0.135	   0.482
04:00:26	   27	0.135	   0.476
04:00:52	   28	0.135	   0.488
04:01:18	   29	0.134	   0.488
04:01:44	   30	0.134	   0.496

------------------------------

04:01:48	Parameters at epoch 30:

04:01:48	Theta:
04:01:48		-2.5805  -1.2559  -0.9876  
04:01:48	Alpha:
04:01:48		 1.3138   0.6439  
04:01:48	Class weight:
04:01:48		 0.7964   2.2556   0.5850   1.7801  

------------------------------

04:02:08	Accuracy on test set with the parameters above: 0.491

