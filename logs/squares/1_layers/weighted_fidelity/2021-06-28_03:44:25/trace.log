03:44:25	Optimizer: adam
03:44:25	Optimizer params: {'lr': 0.02}
03:44:25	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:44:25	nLayers: 1 - nEpochs: 30 - batchSize: 32
03:44:25	Cost: weighted fidelity
03:44:25	Seed: None

------------------------------

03:44:28	epoch	loss	accuracy
03:44:37	    0	0.325	   0.268
03:45:01	    1	0.166	   0.268
03:45:25	    2	0.139	   0.494
03:45:49	    3	0.140	   0.492
03:46:13	    4	0.139	   0.512
03:46:38	    5	0.139	   0.498
03:47:06	    6	0.139	   0.510
03:47:30	    7	0.139	   0.502
03:47:55	    8	0.139	   0.506
03:48:19	    9	0.139	   0.516
03:48:44	   10	0.139	   0.498
03:49:12	   11	0.139	   0.524
03:49:36	   12	0.139	   0.506
03:50:01	   13	0.139	   0.520
03:50:26	   14	0.139	   0.510
03:50:50	   15	0.139	   0.492
03:51:19	   16	0.139	   0.510
03:51:43	   17	0.139	   0.508
03:52:08	   18	0.139	   0.504
03:52:33	   19	0.139	   0.512
03:52:57	   20	0.139	   0.508
03:53:26	   21	0.139	   0.500
03:53:50	   22	0.139	   0.522
03:54:15	   23	0.139	   0.516
03:54:40	   24	0.139	   0.506
03:55:04	   25	0.139	   0.506
03:55:32	   26	0.139	   0.508
03:55:57	   27	0.139	   0.500
03:56:22	   28	0.139	   0.502
03:56:47	   29	0.139	   0.512
03:57:11	   30	0.139	   0.510

------------------------------

03:57:15	Parameters at epoch 30:

03:57:15	Theta:
03:57:15		-0.4973  -0.0801   0.6417  
03:57:15	Alpha:
03:57:15		-2.0724  -0.5099  
03:57:15	Class weight:
03:57:15		 0.5216   1.5235   1.4428   1.3996  

------------------------------

03:57:33	Accuracy on test set with the parameters above: 0.49766666666666665

