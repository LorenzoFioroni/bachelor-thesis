03:49:29	Optimizer: adam
03:49:29	Optimizer params: {'lr': 0.02}
03:49:29	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:49:29	nLayers: 1 - nEpochs: 30 - batchSize: 32
03:49:29	Cost: weighted fidelity
03:49:29	Seed: None

------------------------------

03:49:34	epoch	loss	accuracy
03:49:40	    0	0.344	   0.246
03:50:03	    1	0.196	   0.246
03:50:26	    2	0.162	   0.222
03:50:49	    3	0.146	   0.468
03:51:12	    4	0.139	   0.500
03:51:35	    5	0.138	   0.508
03:52:01	    6	0.138	   0.504
03:52:24	    7	0.138	   0.504
03:52:47	    8	0.138	   0.494
03:53:10	    9	0.138	   0.516
03:53:33	   10	0.138	   0.498
03:53:59	   11	0.138	   0.504
03:54:22	   12	0.138	   0.496
03:54:45	   13	0.138	   0.506
03:55:09	   14	0.138	   0.514
03:55:32	   15	0.138	   0.500
03:55:58	   16	0.138	   0.496
03:56:21	   17	0.138	   0.502
03:56:44	   18	0.138	   0.502
03:57:08	   19	0.138	   0.500
03:57:30	   20	0.138	   0.502
03:57:57	   21	0.138	   0.502
03:58:20	   22	0.138	   0.500
03:58:43	   23	0.138	   0.512
03:59:06	   24	0.138	   0.502
03:59:30	   25	0.138	   0.500
03:59:56	   26	0.138	   0.496
04:00:19	   27	0.138	   0.508
04:00:42	   28	0.138	   0.500
04:01:05	   29	0.138	   0.502
04:01:29	   30	0.138	   0.506

------------------------------

04:01:32	Parameters at epoch 30:

04:01:32	Theta:
04:01:32		-2.6884  -0.0613  -0.6038  
04:01:32	Alpha:
04:01:32		 2.0032   0.5003  
04:01:32	Class weight:
04:01:32		 0.5084   1.5240   1.4378   1.4456  

------------------------------

04:01:49	Accuracy on test set with the parameters above: 0.47

