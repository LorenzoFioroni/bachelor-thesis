03:49:34	Optimizer: adam
03:49:34	Optimizer params: {'lr': 0.02}
03:49:34	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:49:34	nLayers: 1 - nEpochs: 30 - batchSize: 32
03:49:34	Cost: weighted fidelity
03:49:34	Seed: None

------------------------------

03:49:38	epoch	loss	accuracy
03:49:46	    0	0.326	   0.290
03:50:12	    1	0.246	   0.470
03:50:38	    2	0.187	   0.470
03:51:04	    3	0.168	   0.526
03:51:30	    4	0.160	   0.508
03:51:56	    5	0.148	   0.526
03:52:25	    6	0.138	   0.510
03:52:51	    7	0.133	   0.526
03:53:17	    8	0.130	   0.520
03:53:43	    9	0.129	   0.514
03:54:09	   10	0.128	   0.510
03:54:39	   11	0.127	   0.522
03:55:04	   12	0.127	   0.502
03:55:30	   13	0.127	   0.526
03:55:57	   14	0.126	   0.524
03:56:23	   15	0.126	   0.518
03:56:52	   16	0.126	   0.526
03:57:18	   17	0.126	   0.544
03:57:44	   18	0.126	   0.506
03:58:10	   19	0.126	   0.518
03:58:35	   20	0.126	   0.538
03:59:05	   21	0.126	   0.526
03:59:32	   22	0.126	   0.518
03:59:58	   23	0.126	   0.524
04:00:24	   24	0.126	   0.526
04:00:50	   25	0.126	   0.512
04:01:21	   26	0.126	   0.504
04:01:47	   27	0.126	   0.524
04:02:13	   28	0.126	   0.542
04:02:40	   29	0.126	   0.524
04:03:06	   30	0.126	   0.546

------------------------------

04:03:10	Parameters at epoch 30:

04:03:10	Theta:
04:03:10		-2.7061  -0.9790  -1.0478  
04:03:10	Alpha:
04:03:10		-1.0056   0.8029  
04:03:10	Class weight:
04:03:10		 0.6906   2.0175   0.6263   2.1536  

------------------------------

04:03:30	Accuracy on test set with the parameters above: 0.476

