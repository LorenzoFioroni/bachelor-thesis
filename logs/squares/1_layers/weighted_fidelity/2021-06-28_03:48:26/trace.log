03:48:26	Optimizer: adam
03:48:26	Optimizer params: {'lr': 0.02}
03:48:26	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
03:48:26	nLayers: 1 - nEpochs: 30 - batchSize: 32
03:48:26	Cost: weighted fidelity
03:48:26	Seed: None

------------------------------

03:48:30	epoch	loss	accuracy
03:48:39	    0	0.350	   0.268
03:49:05	    1	0.233	   0.268
03:49:31	    2	0.196	   0.268
03:49:58	    3	0.172	   0.276
03:50:24	    4	0.146	   0.530
03:50:50	    5	0.141	   0.530
03:51:20	    6	0.139	   0.540
03:51:46	    7	0.137	   0.540
03:52:12	    8	0.136	   0.546
03:52:38	    9	0.135	   0.540
03:53:04	   10	0.135	   0.550
03:53:34	   11	0.135	   0.548
03:54:00	   12	0.134	   0.540
03:54:26	   13	0.134	   0.542
03:54:53	   14	0.134	   0.540
03:55:21	   15	0.133	   0.542
03:55:51	   16	0.133	   0.540
03:56:18	   17	0.133	   0.540
03:56:44	   18	0.133	   0.542
03:57:10	   19	0.133	   0.542
03:57:36	   20	0.133	   0.548
03:58:06	   21	0.133	   0.542
03:58:32	   22	0.133	   0.544
03:58:57	   23	0.133	   0.546
03:59:23	   24	0.133	   0.542
03:59:49	   25	0.133	   0.540
04:00:19	   26	0.133	   0.540
04:00:45	   27	0.133	   0.540
04:01:11	   28	0.133	   0.540
04:01:37	   29	0.133	   0.540
04:02:03	   30	0.133	   0.542

------------------------------

04:02:06	Parameters at epoch 30:

04:02:06	Theta:
04:02:06		 0.1054   1.8492   0.0233  
04:02:06	Alpha:
04:02:06		 0.6329   0.5418  
04:02:06	Class weight:
04:02:06		 1.3405   0.4969   1.5511   1.5394  

------------------------------

04:02:25	Accuracy on test set with the parameters above: 0.49666666666666665

