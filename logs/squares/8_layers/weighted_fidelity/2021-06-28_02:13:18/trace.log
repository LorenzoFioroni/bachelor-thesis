02:13:18	Optimizer: adam
02:13:18	Optimizer params: {'lr': 0.02}
02:13:18	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:13:18	nLayers: 8 - nEpochs: 30 - batchSize: 32
02:13:18	Cost: weighted fidelity
02:13:18	Seed: None

------------------------------

02:13:31	epoch	loss	accuracy
02:13:52	    0	0.293	   0.384
02:19:50	    1	0.130	   0.710
02:25:51	    2	0.100	   0.762
02:31:51	    3	0.081	   0.796
02:37:52	    4	0.078	   0.814
02:43:52	    5	0.077	   0.824
02:50:02	    6	0.075	   0.842
02:56:02	    7	0.075	   0.846
03:02:02	    8	0.074	   0.832
03:08:03	    9	0.074	   0.840
03:14:08	   10	0.072	   0.848
03:20:20	   11	0.072	   0.854
03:26:21	   12	0.072	   0.852
03:32:19	   13	0.071	   0.860
03:38:20	   14	0.072	   0.838
03:44:19	   15	0.072	   0.850
03:50:30	   16	0.071	   0.846
03:56:31	   17	0.070	   0.862
04:02:34	   18	0.071	   0.870
04:08:39	   19	0.070	   0.860
04:14:40	   20	0.070	   0.882
04:20:55	   21	0.070	   0.862
04:26:58	   22	0.069	   0.880
04:33:01	   23	0.069	   0.870
04:39:04	   24	0.069	   0.868
04:45:06	   25	0.069	   0.866
04:51:23	   26	0.069	   0.882
04:57:29	   27	0.069	   0.886
05:03:36	   28	0.069	   0.868
05:09:38	   29	0.068	   0.876
05:15:40	   30	0.068	   0.878

------------------------------

05:15:52	Parameters at epoch 30:

05:15:52	Theta:
05:15:52		 1.7639  -0.2935  -2.5733  
05:15:52		-0.7246  -0.4326  -0.3879  
05:15:52		 1.3733   0.0047  -0.3211  
05:15:52		 0.9803   0.5091  -1.1065  
05:15:52		-0.7717  -0.9018  -2.1334  
05:15:52		-0.4231  -0.1666  -0.6621  
05:15:52		-1.6922  -0.2413  -0.3121  
05:15:52		-0.3269  -1.4275   0.0267  
05:15:52	Alpha:
05:15:52		-0.0342   1.3787  
05:15:52		 1.0594  -1.0503  
05:15:52		 0.9429   1.3289  
05:15:52		 0.7443  -1.9048  
05:15:52		-0.8338   1.0984  
05:15:52		-0.8201   1.5041  
05:15:52		 0.1069  -0.9231  
05:15:52		-0.1778   0.2695  
05:15:52	Class weight:
05:15:52		 1.0934   1.1886   1.1472   0.6799  

------------------------------

05:16:56	Accuracy on test set with the parameters above: 0.8903333333333333

