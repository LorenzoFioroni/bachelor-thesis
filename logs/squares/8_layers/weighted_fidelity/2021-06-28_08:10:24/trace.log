08:10:24	Optimizer: adam
08:10:24	Optimizer params: {'lr': 0.02}
08:10:24	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
08:10:24	nLayers: 8 - nEpochs: 30 - batchSize: 32
08:10:24	Cost: weighted fidelity
08:10:24	Seed: None

------------------------------

08:10:33	epoch	loss	accuracy
08:10:51	    0	0.318	   0.336
08:15:37	    1	0.137	   0.646
08:20:21	    2	0.096	   0.790
08:25:07	    3	0.080	   0.838
08:29:51	    4	0.079	   0.826
08:34:36	    5	0.077	   0.858
08:39:29	    6	0.076	   0.838
08:44:07	    7	0.074	   0.868
08:48:44	    8	0.073	   0.852
08:53:20	    9	0.074	   0.840
08:57:56	   10	0.073	   0.836
09:02:37	   11	0.071	   0.854
09:07:12	   12	0.071	   0.854
09:11:47	   13	0.069	   0.866
09:16:21	   14	0.070	   0.876
09:20:56	   15	0.069	   0.884
09:25:38	   16	0.068	   0.886
09:30:14	   17	0.068	   0.862
09:34:49	   18	0.069	   0.860
09:39:25	   19	0.068	   0.896
09:43:59	   20	0.067	   0.878
09:48:42	   21	0.067	   0.894
09:53:15	   22	0.066	   0.870
09:57:49	   23	0.066	   0.898
10:02:23	   24	0.066	   0.896
10:06:56	   25	0.066	   0.904
10:11:40	   26	0.067	   0.876
10:16:16	   27	0.065	   0.880
10:20:50	   28	0.065	   0.898
10:25:24	   29	0.065	   0.912
10:29:57	   30	0.065	   0.870

------------------------------

10:30:06	Parameters at epoch 30:

10:30:06	Theta:
10:30:06		 1.4666   0.6822   2.9055  
10:30:06		-0.2616   1.0630  -0.1190  
10:30:06		 1.2417  -0.2817  -0.8054  
10:30:06		 0.5650   1.3019  -0.9387  
10:30:06		-2.1151   2.2476  -0.4200  
10:30:06		 0.9862  -0.1583   0.3181  
10:30:06		-1.2671   0.2840  -1.9171  
10:30:06		-0.1845   1.1635  -2.8562  
10:30:06	Alpha:
10:30:06		 0.7219   0.3344  
10:30:06		-1.1581  -1.6958  
10:30:06		 1.0558  -0.9324  
10:30:06		 0.8548   1.3565  
10:30:06		-0.9322   1.1490  
10:30:06		 1.2394  -0.8354  
10:30:06		 0.9732   0.9795  
10:30:06		-1.2538   1.9749  
10:30:06	Class weight:
10:30:06		 0.7876   1.0075   1.0579   1.0679  

------------------------------

10:30:56	Accuracy on test set with the parameters above: 0.883

