02:10:11	Optimizer: adam
02:10:11	Optimizer params: {'lr': 0.02}
02:10:11	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:10:11	nLayers: 8 - nEpochs: 30 - batchSize: 32
02:10:11	Cost: weighted fidelity
02:10:11	Seed: None

------------------------------

02:10:22	epoch	loss	accuracy
02:10:40	    0	0.360	   0.216
02:15:26	    1	0.146	   0.638
02:20:10	    2	0.114	   0.782
02:24:55	    3	0.097	   0.850
02:29:41	    4	0.085	   0.850
02:34:32	    5	0.075	   0.884
02:39:34	    6	0.073	   0.876
02:44:24	    7	0.072	   0.886
02:49:12	    8	0.072	   0.904
02:53:59	    9	0.071	   0.886
02:58:45	   10	0.071	   0.906
03:03:42	   11	0.070	   0.900
03:08:27	   12	0.072	   0.890
03:13:15	   13	0.069	   0.896
03:18:06	   14	0.069	   0.892
03:22:51	   15	0.069	   0.896
03:27:47	   16	0.068	   0.904
03:32:35	   17	0.068	   0.906
03:37:24	   18	0.069	   0.900
03:42:13	   19	0.068	   0.910
03:46:59	   20	0.067	   0.908
03:51:55	   21	0.067	   0.912
03:56:41	   22	0.066	   0.902
04:01:29	   23	0.065	   0.908
04:06:16	   24	0.065	   0.908
04:11:05	   25	0.065	   0.902
04:16:02	   26	0.063	   0.912
04:20:50	   27	0.063	   0.914
04:25:35	   28	0.062	   0.916
04:30:20	   29	0.062	   0.914
04:35:07	   30	0.061	   0.916

------------------------------

04:35:17	Parameters at epoch 30:

04:35:17	Theta:
04:35:17		-0.3427   0.6913   0.3563  
04:35:17		 0.0706   1.0490  -1.4082  
04:35:17		 0.0053  -0.2332  -1.1228  
04:35:17		 0.3424   1.5945  -0.9366  
04:35:17		 0.2634  -1.6195  -0.8604  
04:35:17		-0.0066  -0.6285  -0.1428  
04:35:17		-1.0294  -1.1760   0.1243  
04:35:17		-2.0833   0.8169  -1.4558  
04:35:17	Alpha:
04:35:17		-0.6696  -1.1152  
04:35:17		 3.2265   0.3335  
04:35:17		 1.3949   0.6464  
04:35:17		-1.0812   1.0139  
04:35:17		-0.3554   1.5743  
04:35:17		 0.7470   0.1057  
04:35:17		 0.3574   0.3009  
04:35:17		 1.0701  -1.3065  
04:35:17	Class weight:
04:35:17		 1.0638   1.0649   0.7880   0.9761  

------------------------------

04:36:11	Accuracy on test set with the parameters above: 0.9086666666666666

