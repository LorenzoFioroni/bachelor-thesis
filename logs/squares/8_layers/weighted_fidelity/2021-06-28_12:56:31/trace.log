12:56:31	Optimizer: adam
12:56:31	Optimizer params: {'lr': 0.02}
12:56:31	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
12:56:31	nLayers: 8 - nEpochs: 30 - batchSize: 32
12:56:31	Cost: weighted fidelity
12:56:31	Seed: None

------------------------------

12:56:39	epoch	loss	accuracy
12:56:54	    0	0.233	   0.398
13:00:56	    1	0.102	   0.794
13:04:59	    2	0.088	   0.854
13:09:03	    3	0.083	   0.872
13:13:06	    4	0.077	   0.878
13:17:10	    5	0.073	   0.912
13:21:22	    6	0.070	   0.910
13:25:26	    7	0.071	   0.878
13:29:31	    8	0.066	   0.916
13:33:35	    9	0.067	   0.912
13:37:41	   10	0.064	   0.910
13:41:55	   11	0.063	   0.918
13:46:00	   12	0.062	   0.928
13:50:08	   13	0.061	   0.908
13:54:13	   14	0.060	   0.910
13:58:17	   15	0.060	   0.920
14:02:30	   16	0.059	   0.922
14:06:34	   17	0.058	   0.930
14:10:39	   18	0.058	   0.920
14:14:44	   19	0.058	   0.924
14:18:50	   20	0.057	   0.920
14:23:02	   21	0.057	   0.926
14:27:07	   22	0.057	   0.926
14:31:12	   23	0.057	   0.922
14:35:17	   24	0.056	   0.916
14:39:22	   25	0.056	   0.916
14:43:35	   26	0.056	   0.922
14:47:40	   27	0.055	   0.916
14:51:46	   28	0.055	   0.926
14:55:51	   29	0.055	   0.918
14:59:56	   30	0.054	   0.920

------------------------------

15:00:05	Parameters at epoch 30:

15:00:05	Theta:
15:00:05		 0.3481   1.8255   0.3538  
15:00:05		 0.4679  -0.9772   0.6070  
15:00:05		 0.1359  -0.8135  -0.2704  
15:00:05		 2.4922   0.3736  -1.4352  
15:00:05		-0.5172   0.6535   1.3582  
15:00:05		 1.6944   0.2073   1.2315  
15:00:05		-0.3840   0.1430  -0.4623  
15:00:05		 0.3344  -1.5718  -1.5287  
15:00:05	Alpha:
15:00:05		-1.2364   0.4102  
15:00:05		-0.7412   1.6291  
15:00:05		-1.6290   0.0871  
15:00:05		 2.0461  -0.0175  
15:00:05		 0.2125   2.7914  
15:00:05		 0.1024  -0.6252  
15:00:05		-0.2708   1.0797  
15:00:05		-0.1728   1.6973  
15:00:05	Class weight:
15:00:05		 0.8326   1.1301   0.9019   1.0684  

------------------------------

15:00:49	Accuracy on test set with the parameters above: 0.9066666666666666

