02:11:34	Optimizer: adam
02:11:34	Optimizer params: {'lr': 0.02}
02:11:34	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:11:34	nLayers: 8 - nEpochs: 30 - batchSize: 32
02:11:34	Cost: weighted fidelity
02:11:34	Seed: None

------------------------------

02:11:44	epoch	loss	accuracy
02:12:02	    0	0.290	   0.316
02:16:50	    1	0.127	   0.674
02:21:38	    2	0.098	   0.762
02:26:25	    3	0.089	   0.814
02:31:13	    4	0.087	   0.802
02:36:01	    5	0.083	   0.846
02:40:58	    6	0.086	   0.842
02:45:44	    7	0.083	   0.828
02:50:31	    8	0.080	   0.852
02:55:16	    9	0.080	   0.850
03:00:02	   10	0.079	   0.860
03:04:58	   11	0.078	   0.858
03:09:47	   12	0.077	   0.846
03:14:35	   13	0.079	   0.854
03:19:22	   14	0.076	   0.852
03:24:12	   15	0.076	   0.844
03:29:12	   16	0.075	   0.864
03:33:59	   17	0.075	   0.854
03:38:49	   18	0.077	   0.878
03:43:37	   19	0.074	   0.858
03:48:26	   20	0.074	   0.858
03:53:23	   21	0.073	   0.860
03:58:13	   22	0.073	   0.858
04:03:02	   23	0.073	   0.860
04:07:52	   24	0.072	   0.862
04:12:44	   25	0.072	   0.864
04:17:43	   26	0.072	   0.864
04:22:34	   27	0.072	   0.878
04:27:25	   28	0.072	   0.868
04:32:13	   29	0.072	   0.870
04:37:01	   30	0.072	   0.856

------------------------------

04:37:12	Parameters at epoch 30:

04:37:12	Theta:
04:37:12		 1.4198   0.6435   0.3814  
04:37:12		-0.6273  -1.4390   0.0955  
04:37:12		-0.7607   0.1565   1.3273  
04:37:12		 1.6762   0.7696  -0.8917  
04:37:12		 0.1269   0.4426   1.8734  
04:37:12		 0.8947  -0.9303   0.7623  
04:37:12		 0.5673   2.2215   1.3165  
04:37:12		-0.5838  -2.4441   1.7571  
04:37:12	Alpha:
04:37:12		 0.5790  -1.3664  
04:37:12		-1.4312  -1.1429  
04:37:12		-0.9308   0.9133  
04:37:12		 0.9214   0.7415  
04:37:12		-0.1504   0.3853  
04:37:12		 0.2597   0.1518  
04:37:12		 0.4947   2.0623  
04:37:12		 0.6701  -0.7293  
04:37:12	Class weight:
04:37:12		 1.1712   1.2141   1.1775   0.6253  

------------------------------

04:38:06	Accuracy on test set with the parameters above: 0.8516666666666667

