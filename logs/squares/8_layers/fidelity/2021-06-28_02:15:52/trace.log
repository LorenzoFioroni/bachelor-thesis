02:15:52	Optimizer: adam
02:15:52	Optimizer params: {'lr': 0.02}
02:15:52	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:15:52	nLayers: 8 - nEpochs: 30 - batchSize: 32
02:15:52	Cost: fidelity
02:15:52	Seed: None

------------------------------

02:16:03	epoch	loss	accuracy
02:16:14	    0	0.513	   0.132
02:17:30	    1	0.187	   0.708
02:18:46	    2	0.149	   0.836
02:20:04	    3	0.132	   0.836
02:21:24	    4	0.119	   0.886
02:22:43	    5	0.116	   0.868
02:24:13	    6	0.118	   0.842
02:25:31	    7	0.110	   0.870
02:26:49	    8	0.106	   0.890
02:28:06	    9	0.103	   0.878
02:29:23	   10	0.101	   0.902
02:30:49	   11	0.094	   0.904
02:32:07	   12	0.090	   0.908
02:33:25	   13	0.087	   0.908
02:34:44	   14	0.089	   0.896
02:36:02	   15	0.086	   0.914
02:37:30	   16	0.084	   0.914
02:38:47	   17	0.084	   0.912
02:40:05	   18	0.083	   0.908
02:41:22	   19	0.084	   0.910
02:42:39	   20	0.084	   0.922
02:44:06	   21	0.084	   0.902
02:45:23	   22	0.081	   0.920
02:46:40	   23	0.082	   0.910
02:47:57	   24	0.081	   0.922
02:49:14	   25	0.080	   0.924
02:50:42	   26	0.080	   0.920
02:52:01	   27	0.080	   0.924
02:53:21	   28	0.080	   0.926
02:54:39	   29	0.079	   0.924
02:55:58	   30	0.079	   0.922

------------------------------

02:56:08	Parameters at epoch 30:

02:56:08	Theta:
02:56:08		 0.8432  -0.4224   0.9124  
02:56:08		 0.9168  -0.5066  -0.0681  
02:56:08		-0.2255  -0.4920  -1.4706  
02:56:08		-3.4228   0.5973  -0.9238  
02:56:08		-0.4578  -0.3834   1.8565  
02:56:08		-0.5518   0.6305  -0.5205  
02:56:08		-1.2526   1.7902  -0.4451  
02:56:08		 0.8782  -1.1231  -0.9181  
02:56:08	Alpha:
02:56:08		-0.5205  -0.2471  
02:56:08		-3.7857  -2.4601  
02:56:08		 0.0807   1.8555  
02:56:08		 0.4569   0.1447  
02:56:08		-1.7065   1.9164  
02:56:08		 0.3275   0.4927  
02:56:08		-1.0838  -1.4364  
02:56:08		 0.8597  -0.7474  

------------------------------

02:57:02	Accuracy on test set with the parameters above: 0.917

