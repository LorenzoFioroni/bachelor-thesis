02:15:12	Optimizer: adam
02:15:12	Optimizer params: {'lr': 0.02}
02:15:12	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:15:12	nLayers: 8 - nEpochs: 30 - batchSize: 32
02:15:12	Cost: fidelity
02:15:12	Seed: None

------------------------------

02:15:23	epoch	loss	accuracy
02:15:34	    0	0.381	   0.422
02:16:55	    1	0.213	   0.680
02:18:17	    2	0.163	   0.748
02:19:38	    3	0.144	   0.790
02:20:59	    4	0.127	   0.836
02:22:21	    5	0.120	   0.866
02:23:52	    6	0.114	   0.878
02:25:13	    7	0.112	   0.890
02:26:35	    8	0.108	   0.892
02:27:56	    9	0.104	   0.904
02:29:17	   10	0.102	   0.908
02:30:48	   11	0.099	   0.908
02:32:10	   12	0.096	   0.896
02:33:30	   13	0.095	   0.910
02:34:52	   14	0.094	   0.918
02:36:13	   15	0.095	   0.918
02:37:45	   16	0.092	   0.892
02:39:07	   17	0.093	   0.880
02:40:28	   18	0.092	   0.904
02:41:49	   19	0.092	   0.916
02:43:11	   20	0.091	   0.900
02:44:43	   21	0.091	   0.890
02:46:04	   22	0.091	   0.916
02:47:27	   23	0.092	   0.878
02:48:48	   24	0.091	   0.916
02:50:10	   25	0.091	   0.906
02:51:41	   26	0.091	   0.898
02:53:02	   27	0.090	   0.898
02:54:24	   28	0.090	   0.902
02:55:46	   29	0.090	   0.908
02:57:08	   30	0.090	   0.902

------------------------------

02:57:18	Parameters at epoch 30:

02:57:18	Theta:
02:57:18		-0.2897  -0.3641   0.9514  
02:57:18		 1.4982  -1.7074  -1.7211  
02:57:18		-0.5098   1.8199   0.4377  
02:57:18		 0.8794   1.6707  -1.6521  
02:57:18		-1.3007  -0.7663   0.3332  
02:57:18		 1.2273  -1.9398  -0.5968  
02:57:18		 0.3087  -1.8329  -0.9180  
02:57:18		-1.3159   0.4450   1.9165  
02:57:18	Alpha:
02:57:18		-2.0611  -2.0146  
02:57:18		-0.4346   0.9515  
02:57:18		-1.1996  -1.8330  
02:57:18		-1.5970  -1.3536  
02:57:18		-0.1681   1.3120  
02:57:18		 0.9591  -1.1866  
02:57:18		-0.1600   2.2405  
02:57:18		 1.0503  -0.5861  

------------------------------

02:58:10	Accuracy on test set with the parameters above: 0.896

