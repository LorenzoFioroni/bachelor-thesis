02:14:32	Optimizer: adam
02:14:32	Optimizer params: {'lr': 0.02}
02:14:32	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:14:32	nLayers: 8 - nEpochs: 30 - batchSize: 32
02:14:32	Cost: fidelity
02:14:32	Seed: None

------------------------------

02:14:41	epoch	loss	accuracy
02:14:51	    0	0.600	   0.120
02:16:01	    1	0.269	   0.522
02:17:11	    2	0.223	   0.666
02:18:21	    3	0.205	   0.652
02:19:32	    4	0.182	   0.684
02:20:42	    5	0.165	   0.740
02:22:01	    6	0.144	   0.784
02:23:11	    7	0.120	   0.828
02:24:21	    8	0.107	   0.888
02:25:32	    9	0.105	   0.854
02:26:43	   10	0.099	   0.894
02:28:02	   11	0.100	   0.876
02:29:13	   12	0.098	   0.902
02:30:24	   13	0.095	   0.884
02:31:34	   14	0.093	   0.908
02:32:45	   15	0.091	   0.910
02:34:05	   16	0.091	   0.910
02:35:15	   17	0.088	   0.908
02:36:26	   18	0.087	   0.910
02:37:36	   19	0.085	   0.922
02:38:47	   20	0.083	   0.908
02:40:06	   21	0.082	   0.916
02:41:17	   22	0.081	   0.916
02:42:27	   23	0.080	   0.928
02:43:38	   24	0.080	   0.920
02:44:49	   25	0.079	   0.928
02:46:08	   26	0.078	   0.932
02:47:19	   27	0.078	   0.934
02:48:30	   28	0.077	   0.936
02:49:41	   29	0.077	   0.938
02:50:51	   30	0.077	   0.932

------------------------------

02:51:00	Parameters at epoch 30:

02:51:00	Theta:
02:51:00		-1.2180  -1.9614   2.2281  
02:51:00		 0.5748   0.8631  -1.2939  
02:51:00		-0.1561   1.6206  -0.1098  
02:51:00		-0.0991   0.8766  -0.2946  
02:51:00		 0.8565  -0.6229  -0.4419  
02:51:00		 0.0060   1.8799  -0.7998  
02:51:00		 0.4317   1.1399  -1.8899  
02:51:00		 1.0245  -0.0139   0.0839  
02:51:00	Alpha:
02:51:00		 1.8502  -1.4551  
02:51:00		-1.1387  -3.1723  
02:51:00		-0.7393   0.2656  
02:51:00		-0.4263   1.4463  
02:51:00		-0.8846   1.0835  
02:51:00		-1.2903  -0.8058  
02:51:00		 0.9138   1.9025  
02:51:00		-0.7549  -0.8836  

------------------------------

02:51:46	Accuracy on test set with the parameters above: 0.9153333333333333

