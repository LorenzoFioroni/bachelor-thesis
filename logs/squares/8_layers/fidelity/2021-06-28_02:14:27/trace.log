02:14:27	Optimizer: adam
02:14:27	Optimizer params: {'lr': 0.02}
02:14:27	DataSet: squares - nTrain: 500 - nValid: 0 - nTest: 3000
02:14:27	nLayers: 8 - nEpochs: 30 - batchSize: 32
02:14:27	Cost: fidelity
02:14:27	Seed: None

------------------------------

02:14:40	epoch	loss	accuracy
02:14:54	    0	0.433	   0.394
02:16:34	    1	0.173	   0.756
02:18:13	    2	0.138	   0.864
02:19:52	    3	0.126	   0.866
02:21:33	    4	0.120	   0.886
02:23:13	    5	0.116	   0.874
02:25:03	    6	0.115	   0.886
02:26:43	    7	0.116	   0.880
02:28:22	    8	0.106	   0.898
02:30:01	    9	0.104	   0.916
02:31:41	   10	0.102	   0.910
02:33:34	   11	0.100	   0.898
02:35:17	   12	0.098	   0.908
02:36:57	   13	0.099	   0.900
02:38:38	   14	0.100	   0.906
02:40:18	   15	0.099	   0.894
02:42:10	   16	0.096	   0.910
02:43:51	   17	0.095	   0.906
02:45:31	   18	0.095	   0.912
02:47:11	   19	0.093	   0.910
02:48:51	   20	0.093	   0.910
02:50:42	   21	0.092	   0.914
02:52:23	   22	0.091	   0.916
02:54:03	   23	0.090	   0.914
02:55:43	   24	0.089	   0.908
02:57:23	   25	0.088	   0.916
02:59:14	   26	0.086	   0.912
03:00:54	   27	0.085	   0.918
03:02:34	   28	0.084	   0.912
03:04:14	   29	0.082	   0.918
03:05:54	   30	0.081	   0.922

------------------------------

03:06:05	Parameters at epoch 30:

03:06:05	Theta:
03:06:05		-0.1576  -0.6697  -1.5727  
03:06:05		-1.6986  -0.4171  -2.3228  
03:06:05		-0.3710  -1.6267   0.0971  
03:06:05		-1.0275  -0.7612   0.8320  
03:06:05		-0.6140   1.3757   0.9589  
03:06:05		 2.5561  -0.1114   0.3582  
03:06:05		-1.0324  -1.3454  -1.3507  
03:06:05		-0.1166  -3.0748  -1.5325  
03:06:05	Alpha:
03:06:05		 1.2811  -0.3999  
03:06:05		 1.0016   0.4712  
03:06:05		 3.0826   0.2128  
03:06:05		 0.8445  -1.6792  
03:06:05		 0.2962  -0.7021  
03:06:05		 0.2524   0.5296  
03:06:05		 0.6378  -0.8980  
03:06:05		-1.6008   1.5655  

------------------------------

03:07:12	Accuracy on test set with the parameters above: 0.9116666666666666

