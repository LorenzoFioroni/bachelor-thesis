22:34:04	Optimizer: adam
22:34:04	Optimizer params: {'lr': 0.03}
22:34:04	DataSet: three circles - nTrain: 500 - nValid: 0 - nTest: 3000
22:34:04	nLayers: 8 - nEpochs: 30 - batchSize: 15
22:34:04	Cost: weighted fidelity
22:34:04	Seed: None

------------------------------

22:34:14	epoch	loss	accuracy
22:34:31	    0	0.335	   0.262
22:39:13	    1	0.144	   0.672
22:43:58	    2	0.123	   0.756
22:48:43	    3	0.123	   0.796
22:53:26	    4	0.115	   0.776
22:58:11	    5	0.116	   0.810
23:03:05	    6	0.113	   0.806
23:07:48	    7	0.115	   0.800
23:12:33	    8	0.109	   0.798
23:17:17	    9	0.107	   0.796
23:22:02	   10	0.107	   0.776
23:26:56	   11	0.106	   0.814
23:31:40	   12	0.107	   0.812
23:36:24	   13	0.100	   0.828
23:41:08	   14	0.099	   0.804
23:45:54	   15	0.092	   0.830
23:50:49	   16	0.090	   0.838
23:55:34	   17	0.086	   0.848
00:00:21	   18	0.083	   0.848
00:05:07	   19	0.081	   0.854
00:09:54	   20	0.078	   0.856
00:14:50	   21	0.076	   0.866
00:19:37	   22	0.074	   0.870
00:24:22	   23	0.069	   0.886
00:29:08	   24	0.068	   0.888
00:33:54	   25	0.067	   0.864
00:38:48	   26	0.066	   0.868
00:43:36	   27	0.064	   0.878
00:48:23	   28	0.063	   0.872
00:53:07	   29	0.061	   0.886
00:57:51	   30	0.061	   0.876

------------------------------

00:58:01	Parameters at epoch 30:

00:58:01	Theta:
00:58:01		 0.1563  -0.6607   1.1076  
00:58:01		-0.7466  -0.5863   2.0467  
00:58:01		 0.8732   0.5054  -1.0942  
00:58:01		-1.6077   0.4759   3.1697  
00:58:01		-0.5298  -1.0391   1.0662  
00:58:01		-0.1507  -1.3383  -0.4799  
00:58:01		 1.6646  -0.9368  -1.7123  
00:58:01		 0.5752   0.8311   0.5653  
00:58:01	Alpha:
00:58:01		-0.2247  -1.0088  
00:58:01		 0.0931  -1.0373  
00:58:01		 1.2181   0.6049  
00:58:01		 2.1877  -0.1441  
00:58:01		 1.2293  -0.9550  
00:58:01		-0.7892   1.6875  
00:58:01		 3.6011  -3.5352  
00:58:01		 1.0544   1.1674  
00:58:01	Class weight:
00:58:01		 0.7696   1.1192   1.0654   0.9728  

------------------------------

00:58:55	Accuracy on test set with the parameters above: 0.8896666666666667

