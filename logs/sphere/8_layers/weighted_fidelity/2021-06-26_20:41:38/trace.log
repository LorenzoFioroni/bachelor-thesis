20:41:38	Optimizer: adam
20:41:38	Optimizer params: {'lr': 0.03}
20:41:38	DataSet: sphere - nTrain: 500 - nValid: 0 - nTest: 3000
20:41:38	nLayers: 8 - nEpochs: 30 - batchSize: 32
20:41:38	Cost: weighted fidelity
20:41:38	Seed: None

------------------------------

20:41:42	epoch	loss	accuracy
20:41:51	    0	0.361	   0.470
20:44:32	    1	0.197	   0.718
20:47:14	    2	0.158	   0.754
20:49:55	    3	0.130	   0.816
20:52:38	    4	0.120	   0.852
20:55:20	    5	0.120	   0.842
20:58:07	    6	0.117	   0.858
21:00:49	    7	0.115	   0.840
21:03:32	    8	0.112	   0.858
21:06:15	    9	0.108	   0.866
21:08:58	   10	0.108	   0.858
21:11:45	   11	0.106	   0.862
21:14:28	   12	0.106	   0.866
21:17:11	   13	0.104	   0.864
21:19:54	   14	0.104	   0.874
21:22:36	   15	0.102	   0.860
21:25:24	   16	0.102	   0.856
21:28:06	   17	0.100	   0.872
21:30:50	   18	0.100	   0.876
21:33:33	   19	0.100	   0.858
21:36:17	   20	0.099	   0.880
21:39:04	   21	0.099	   0.874
21:41:48	   22	0.098	   0.876
21:44:31	   23	0.098	   0.866
21:47:15	   24	0.097	   0.880
21:49:58	   25	0.097	   0.872
21:52:46	   26	0.097	   0.880
21:55:28	   27	0.096	   0.874
21:58:11	   28	0.095	   0.876
22:00:54	   29	0.095	   0.876
22:03:37	   30	0.095	   0.880

------------------------------

22:03:42	Parameters at epoch 30:

22:03:42	Theta:
22:03:42		 0.5130  -1.3187   0.9288  
22:03:42		 0.3389   0.3305  -0.8032  
22:03:42		-0.3208  -1.7803  -0.9064  
22:03:42		 1.5411   0.3575  -0.0967  
22:03:42		 0.8289   0.9131   0.0725  
22:03:42		 1.7755   0.9203  -0.3006  
22:03:42		-0.0248  -1.4915   1.2683  
22:03:42		-0.9565   1.3525  -0.4158  
22:03:42	Alpha:
22:03:42		 0.2017   1.3696   0.8497  
22:03:42		-1.3029   0.0175  -0.4496  
22:03:42		 1.2620   0.3110  -0.8479  
22:03:42		 1.9273  -1.5372   2.2911  
22:03:42		-0.0122   0.8380   1.1562  
22:03:42		 1.1075   0.3294  -0.3811  
22:03:42		-1.0476   0.9694   1.4872  
22:03:42		-1.7586   2.5689  -0.0027  
22:03:42	Class weight:
22:03:42		 1.1030   1.0532  

------------------------------

22:04:08	Accuracy on test set with the parameters above: 0.8416666666666667

