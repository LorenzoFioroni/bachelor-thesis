07:21:51	Optimizer: adam
07:21:51	Optimizer params: {'lr': 0.02}
07:21:51	DataSet: binary annulus - nTrain: 500 - nValid: 0 - nTest: 3000
07:21:51	nLayers: 1 - nEpochs: 40 - batchSize: 48
07:21:51	Cost: weighted fidelity
07:21:51	Seed: None

------------------------------

07:21:53	epoch	loss	accuracy
07:21:58	    0	0.508	   0.492
07:22:11	    1	0.409	   0.492
07:22:23	    2	0.342	   0.492
07:22:36	    3	0.300	   0.476
07:22:49	    4	0.267	   0.506
07:23:02	    5	0.255	   0.508
07:23:17	    6	0.250	   0.508
07:23:30	    7	0.250	   0.506
07:23:43	    8	0.250	   0.494
07:23:56	    9	0.250	   0.508
07:24:09	   10	0.250	   0.548
07:24:24	   11	0.250	   0.498
07:24:37	   12	0.250	   0.510
07:24:50	   13	0.250	   0.498
07:25:03	   14	0.250	   0.530
07:25:16	   15	0.250	   0.600
07:25:32	   16	0.250	   0.510
07:25:45	   17	0.250	   0.512
07:25:58	   18	0.250	   0.516
07:26:11	   19	0.250	   0.528
07:26:24	   20	0.250	   0.594
07:26:39	   21	0.250	   0.510
07:26:52	   22	0.249	   0.510
07:27:05	   23	0.250	   0.504
07:27:18	   24	0.249	   0.528
07:27:31	   25	0.249	   0.528
07:27:46	   26	0.249	   0.520
07:27:59	   27	0.249	   0.546
07:28:12	   28	0.249	   0.506
07:28:25	   29	0.250	   0.496
07:28:38	   30	0.249	   0.546
07:28:53	   31	0.250	   0.546
07:29:06	   32	0.249	   0.540
07:29:19	   33	0.250	   0.524
07:29:33	   34	0.249	   0.524
07:29:46	   35	0.249	   0.512
07:30:01	   36	0.250	   0.518
07:30:14	   37	0.249	   0.518
07:30:27	   38	0.249	   0.528
07:30:40	   39	0.249	   0.546
07:30:53	   40	0.249	   0.506

------------------------------

07:30:55	Parameters at epoch 40:

07:30:55	Theta:
07:30:55		-0.9710   1.0412   1.2500  
07:30:55	Alpha:
07:30:55		 0.2126   0.0975  
07:30:55	Class weight:
07:30:55		 0.6558   2.0465  

------------------------------

07:31:05	Accuracy on test set with the parameters above: 0.4856666666666667

