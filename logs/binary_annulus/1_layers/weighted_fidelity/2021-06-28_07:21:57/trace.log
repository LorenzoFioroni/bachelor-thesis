07:21:57	Optimizer: adam
07:21:57	Optimizer params: {'lr': 0.02}
07:21:57	DataSet: binary annulus - nTrain: 500 - nValid: 0 - nTest: 3000
07:21:57	nLayers: 1 - nEpochs: 40 - batchSize: 48
07:21:57	Cost: weighted fidelity
07:21:57	Seed: None

------------------------------

07:21:59	epoch	loss	accuracy
07:22:03	    0	0.315	   0.496
07:22:16	    1	0.254	   0.496
07:22:28	    2	0.251	   0.504
07:22:41	    3	0.250	   0.536
07:22:54	    4	0.249	   0.538
07:23:06	    5	0.248	   0.536
07:23:21	    6	0.248	   0.550
07:23:34	    7	0.248	   0.536
07:23:47	    8	0.248	   0.540
07:23:59	    9	0.248	   0.550
07:24:12	   10	0.248	   0.544
07:24:27	   11	0.248	   0.540
07:24:40	   12	0.248	   0.544
07:24:52	   13	0.248	   0.544
07:25:05	   14	0.248	   0.546
07:25:18	   15	0.248	   0.546
07:25:33	   16	0.248	   0.538
07:25:46	   17	0.248	   0.538
07:25:59	   18	0.248	   0.548
07:26:11	   19	0.248	   0.542
07:26:24	   20	0.248	   0.538
07:26:39	   21	0.248	   0.542
07:26:52	   22	0.248	   0.548
07:27:05	   23	0.248	   0.544
07:27:18	   24	0.248	   0.544
07:27:30	   25	0.248	   0.538
07:27:45	   26	0.248	   0.546
07:27:58	   27	0.248	   0.550
07:28:11	   28	0.248	   0.544
07:28:23	   29	0.248	   0.546
07:28:36	   30	0.248	   0.544
07:28:51	   31	0.248	   0.544
07:29:04	   32	0.248	   0.542
07:29:17	   33	0.248	   0.540
07:29:30	   34	0.248	   0.544
07:29:43	   35	0.248	   0.538
07:29:58	   36	0.248	   0.540
07:30:11	   37	0.248	   0.536
07:30:24	   38	0.248	   0.544
07:30:37	   39	0.248	   0.542
07:30:50	   40	0.248	   0.546

------------------------------

07:30:52	Parameters at epoch 40:

07:30:52	Theta:
07:30:52		 0.7471  -1.3701   3.2843  
07:30:52	Alpha:
07:30:52		 1.0939  -0.2058  
07:30:52	Class weight:
07:30:52		 0.8338   1.2495  

------------------------------

07:31:01	Accuracy on test set with the parameters above: 0.49066666666666664

